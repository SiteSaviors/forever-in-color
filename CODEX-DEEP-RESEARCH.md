Wondertone UX Redesign & Optimization Proposal
1. Executive Summary
Recommended Experience Model: We propose Option B – a Hybrid “Art Studio” UX, combining a brief guided stepper with an immersive canvas workspace. This approach keeps an initial orientation (upload & quick style pick) but then transitions into a single studio screen where the artwork preview is always visible and tools (size, frame, AR add-on) are docked around it. This balances guidance and flexibility, expected to reduce time-to-first-preview by ~30% (by auto-generating a preview immediately after upload) and to increase conversion by keeping the user’s edited canvas in constant view (driving emotional engagement and purchase intent).

Key Outcomes: The first AI preview will now appear within seconds of upload (no extra clicks), providing an instant “wow” moment. The studio layout minimizes context-switching – users can tweak options (size, frame, AR video) in one place, with a persistent bottom bar to easily add to cart. By defaulting users to the physical canvas path (and making the digital-download option a subtle secondary action), we expect more users to proceed to checkout for a canvas purchase.

Top 5 Implementation Moves: 1. Instant Preview Generation: Automatically generate a preview for the top recommended art style as soon as a photo is uploaded, eliminating the manual “Generate” step[1]. This dramatically cuts the wait before seeing results. 2. “Art Studio” Interface Merge: Consolidate the current step 2 (canvas size) and step 3 (customizations) into a single studio screen where the AI-generated canvas preview is always visible. Tools like size selection, frame toggle, and the “Living Memory” AR option will be docked alongside the preview for real-time updates. 3. Persistent Bottom Action Bar: Implement a fixed bottom bar (especially on mobile) showing the running price total and a prominent “Add to Cart/Checkout” button. This bar will be accessible as soon as the user enters the studio/customization phase, staying within thumb reach at all times for an easy checkout[2]. 4. Guest Checkout & Post-Purchase Sign-in: Allow users to create and preview art without any upfront login. Only request an email at purchase, and then offer account creation via magic link post-purchase. This preserves the low-friction flow (token purchases for downloads already require login as a special case[3]) while still tying orders to an email for follow-up. 5. Demote Digital-Only Path: Make the canvas purchase the clear default. The option to download a watermark-free digital image will be kept, but as a small link or secondary button (instead of an equal CTA)[4]. This ensures focus on the physical product conversion without eliminating the upsell for those who want a digital copy.

By executing these moves, we anticipate faster “time to wow” (getting users to their first preview quickly) and a smoother, more engaging journey to purchase. We expect a lift in the percentage of users reaching a preview (north-star KPI) and an improvement in overall purchase conversion, thanks to an intuitive, visually-driven studio experience.

2. Experience Models – Comparison & Decision
To determine the optimal UX, we explored three models: A) Accordion 2.0, B) Hybrid “Art Studio”, and C) Full Studio. Below we sketch each with pros/cons and complexity, then select the best fit.

A. Accordion 2.0 – Improved Step-by-Step
Layout/Wireframe:

Step 1: Upload Photo & Choose Style [Expanded] – (Preview visible here)  
Step 2: Canvas Size & Orientation [Collapsed until Step 1 done]  
Step 3: Customizations (Frame, “Living Memory” AR) [Collapsed]  
Step 4: Review & Checkout [Collapsed until prior done]  

[ Persistent preview thumbnail ] (e.g. a small sticky preview in corner, always showing latest chosen style)
In this model, we retain a clear four-step flow[5] but refine it. The steps become an accordion: only Step 1 is open initially; as the user completes it, the next panel expands. The canvas preview remains visible even as you scroll – for example, a thumbnail or fixed preview pane updates as styles or options change.

Pros: Familiar guided progression – users always know what to do next. Keeps cognitive load low by focusing on one step at a time. Implementation is incremental (build on the existing ProductStepsManager gating[6]) and low-risk. The persistent preview ensures the art is never “out of sight,” preserving excitement even while adjusting size or add-ons.

Cons: Still somewhat linear – could feel form-like. Users needing to go back a step must click the accordion header (added friction). The preview, if only a small thumbnail when steps 2–4 are open, might not be large enough for detailed appreciation. While faster than the original (we’d auto-generate the preview in Step 1), it doesn’t fully eliminate step transitions.

Complexity: Low to moderate. We’d reuse the current structure, tweaking ProductStepWrapper to keep content mounted (so state isn’t reset) and adding a CSS sticky preview element. Minimal state refactoring required – mostly UI work.

B. Hybrid “Art Studio” – Guided Entry, Then Single-Screen Studio
Layout/Wireframe:

Top: Step indicator “1 – Create, 2 – Customize, 3 – Checkout” (or similar, just for orientation)

[Step 1 panel: Upload + Style selection] (full screen overlay or section)
--> Upon style selection, transition into Studio mode:

[ Main Canvas Preview – large and central ]
[ Tools docked: Style thumbnails on left (collapsible), Options on right (size, frame, AR toggles), etc. ]
[ Persistent bottom bar: “Add to Cart - $Price” and maybe undo/redo if needed ]

Checkout slide or modal can appear for Step 3.
In this model, the user is given a gentle introduction (a brief Step 1 UI to upload and pick an initial style). After that, we drop the obvious “steps” and show a full canvas studio: the uploaded image transformed in their chosen style, displayed prominently. Around it are docked tool panels – for instance, a sidebar of other styles to try, and a panel for canvas size, frame color, and the AR video toggle. A sticky bottom bar shows price updates and the primary action (Add to Cart or Proceed) at all times.

Pros: Highly visual and interactive – the artwork is always center-stage, reinforcing the product’s value. Users can tweak multiple settings without jumping back and forth between screens, likely increasing engagement time. The persistent bottom CTA and live price ensure clarity on how to proceed and what the cost is. This design is modern and “app-like,” which fits the tech-forward, cool vibe (7/10 tech on brand scale) the brand aspires to. By blending steps 2 and 3 into one studio, we reduce friction – e.g. changing size immediately updates the preview and price in one view.

Cons: Higher implementation complexity than A – essentially requires refactoring the flow management (the state logic for steps needs to support parallel interactions). There is a risk of overwhelming some users with too many visible tools at once (mitigated by sensible defaults and maybe progressive disclosure, like panels that open one at a time). We must carefully design responsive behavior so that on mobile the docks collapse into accessible drawers or accordions.

Complexity: Moderate to high. This will involve reorganizing components (merging CanvasConfigurationStep and CustomizationStep into one interface). State management might need a context provider to allow all tools to access and update the shared product state (the groundwork for this is planned in useProductFlow and context slices[7]). Expect significant CSS layout work (e.g., using a grid or flex container for the canvas and side panels) and thorough testing across devices. However, it builds on the existing foundations (we’re not starting from scratch – we will reuse components like the Style grid, size selector, etc., just re-arranged).

C. Full Studio (Single Screen) – All-in-One Creator
Layout/Wireframe:

[Header: Logo, maybe account icon, etc.]

[Canvas Preview – large center stage]

[Top or left: Style picker thumbnails (scrollable list or carousel)]
[Right side: Options panel (size, orientation, frame, AR, etc.)]
[Bottom: Cart summary bar with price & Checkout button]

(No formal step indicators – it’s a design workspace from the start)
This model removes the notion of steps entirely. The user lands directly into a creation studio. They might first see an upload prompt overlay on the canvas area. Once a photo is in, the interface shows all controls in one screen. It’s akin to a design software layout: the user can click between styles, adjust options, and see the result instantly, then click the checkout button when satisfied.

Pros: Minimum friction – everything is accessible as needed, no “Next” buttons until the final checkout. Power-users or returning users would love the immediacy (they can upload and then freely play with all settings). It feels very modern and could maximize time-on-site interacting with the product (which may correlate with higher likelihood to purchase a canvas). There’s zero context switching – the creation and customization is fully unified.

Cons: Potentially overwhelming for new users. With no guided steps, someone might not know where to start (we’d need excellent default prompts, like a glowing upload area, then highlights on the next suggested action). There’s a higher chance a user might skip an option (e.g., forget to choose a size if we don’t enforce a sequence). From a technical standpoint, all components must be loaded upfront or on-demand, which can increase initial load (though we can lazy-load panels). Also, maintaining all states concurrently (image, previews, size, frame, etc.) and handling their interdependencies (e.g., changing orientation might need regenerating previews) adds complexity.

Complexity: High. This is a significant departure from the current flow. We would need to heavily refactor or remove the step management system and ensure all UI elements can coexist without stepping on each other’s state. The testing matrix is larger (many combinations of actions could happen in any order). It’s doable, but it’s essentially a redesign of the application’s structure, and would require careful QA to not break the underlying business logic (e.g., the order calculation, preview caching, etc.).

Decision: Adopt Hybrid “Art Studio” (Option B)
We choose Option B as the best path. It offers a strong middle ground – guiding the user just enough (so they aren’t lost at start) while delivering the wow factor of a design studio once their art is generated. This model directly supports our primary goal: minimize time to first preview and keep the user engaged through purchase. The initial brief step ensures even non-techy users get started easily (upload & a suggested style). Then the studio mode caters to the exploratory nature of the product – users can see their canvas in different forms quickly, which encourages them to find a combination they love (driving them to buy).

From a conversion perspective, having the canvas always visible is powerful: the more the user sees their own photo turned art, the more likely they are to form an emotional attachment and complete the purchase. Option B also puts the purchase CTA and price always in view (via the bottom bar), gently nudging users toward checkout at any moment they feel “this is it.” Compared to Accordion (A), the hybrid studio removes an extra click or two (size and add-ons can be adjusted without hitting “Next” multiple times) and feels more instantaneous. And it avoids the risk of Option C where a newcomer might be overwhelmed by too many controls at once – we still introduce them stepwise (upload → style, then the rest).

In terms of KPI impact, we expect Option B to notably improve % of users reaching a first preview (because the flow after upload is seamless and the preview comes up automatically) and to likely improve the overall conversion rate by making the customization fun and easy rather than a chore. While Option B is somewhat complex to implement, the ROI in user experience justifies it. We will mitigate the dev complexity by leveraging the existing code (e.g., repurposing the context state logic and many UI components) and tackling the changes in phases (outlined in the Implementation Plan).

3. First-Five-Seconds & Auth Strategy
Hero-to-Upload Path: Our goal is that within the first 5 seconds on the site, the user engages with uploading a photo. The landing/homepage will have a prominent, singular call-to-action: a “Start Creating” or “Upload Your Photo” button in the hero section. This button currently leads to the Product page (the configurator)[8], and we will ensure it stays front-and-center, visually dominant with the brand’s vibrant gradient style. Upon clicking, the user is either taken directly into the upload interface or (if already on the product page) the file picker opens immediately. Essentially, the user should go from landing to seeing an upload dialog almost instantly. Any distracting secondary links or content on the hero will be minimized or moved below the fold – the first action is unequivocally to upload an image. For instance, on desktop the header “Create Art” link and “Start Creating” button will both navigate to the uploader; on mobile, the menu collapses to emphasize the CTA. We’ll use supportive microcopy near the CTA like “Transform your own photo into art – try it now!” to entice the click.

Once on the upload step, we streamline it further: the upload dropzone will be immediately visible (no extra modals or pages in between). The design already uses a flashy drag-and-drop card with an “UPLOAD PHOTO” / “TRANSFORM YOUR PHOTO” button[9] – we’ll keep that, possibly renaming the mobile label to “Upload Photo” everywhere for consistency and immediacy. We ensure the file input accepts capture from camera on mobile[10] so even phone users can snap a pic instantly. In short, from hitting the site to uploading, there is one clear path and zero account hurdles.

Auth Strategy – Guest First, Account Later: We will not force sign-up/login during the creative flow. Users can go from upload to customization to checkout as guests, which aligns with the philosophy “let them see value before asking for commitment.” The only place we’ll require authentication is when it’s absolutely necessary: for instance, if a user attempts to purchase token credits (for downloads) the system currently needs a logged-in user (the code checks if (!user) return to disable token purchase[3]). In those cases, we’ll trigger a gentle prompt or modal asking for a quick sign-in (or even better, offer to continue with email and send a magic link).

For the main purchase path (physical canvas), we plan to treat it as a guest checkout. The checkout form (which collects shipping address, email, payment, etc.) will collect an email address for receipt and order tracking. After a successful purchase, we implement a post-purchase account creation via magic link. Concretely, upon checkout success we can leverage Supabase or our auth system to send the user an email saying “Click to activate your account and save your artwork” – tying it to the provided email. This way, the user has now experienced the product’s value (they’ve made a purchase or at least seen their art previews) and will be more receptive to creating an account to, say, access their order status or download their images. If they ignore it, no problem – we still fulfill the order. This strategy removes any login friction from the funnel’s critical path and likely increases conversion. It’s justified by the data we have in code: accounts are mainly needed for token management and storing past previews, which are nice-to-have but not required upfront[11].

We will, however, track user identity once they do provide an email. If a guest purchases, we’ll ensure that email is used to either retroactively create an account or at least associate their order and any generated images with a record in our database for later retrieval. Our assumption is that Stripe or our payment flow will supply us an email at minimum.

Empty States & Playful Loading Copy: Throughout the UX, we’ll use warm, encouraging microcopy to keep users engaged (in line with the brand’s playful tone, 5/10). For example: - Before Upload (Empty State): In the upload panel, if no image is selected yet, show a message like: “🎨 Ready to create something amazing? Upload a photo to begin!” This sits inside the dropzone as a prompt. We can also list a few supported file tips in a friendly way, e.g., “(PNG or JPG, max 10MB) – we’ll handle the magic.” - During Upload: While the image is uploading or being analyzed for orientation, we replace the button text with a fun loading phrase. Currently it says “CREATING MAGIC” with a spinner[12] – we’ll keep that, as it nicely fits the theme. We might even add a subtle line like “Uploading your photo…” or “Analyzing image…” in smaller text below if the upload takes more than a second or two, just to inform the user. - Preview Generation Loading: This is a critical moment to reassure the user. Instead of a generic “Loading…”, we’ll use something like “✨ Painting your photo…” or “One moment while we create your art…”. For example, as each style preview is generating, a card can say “Applying art style – almost there!” with perhaps an animated sparkle icon. If generation is super fast this may not be seen long, but it’s good to have. We will avoid technical terms; instead of “Calling AI API”, it’ll be “Unleashing our AI artist…”. This keeps excitement up. - Slow Generation Fallback: If a preview is taking unusually long (> ~8 seconds), we’ll add a bit of humorous encouragement. E.g., “🖌️ Our AI is adding extra detail... hang tight!” or “This is taking a little longer – great art takes time 😉”. This can be in a small toast or in the preview card itself. Anything to prevent the user from feeling stuck. - No Styles Recommended / Edge case: If for some reason no styles load (say an error), we’ll show an empty state in the style selector like: “Oops, something went wrong loading styles. Try again in a moment.” with a retry button. But normally, we’ll always have at least default styles.

Overall, the language will remain confident + premium, with a dash of warmth. We want users to feel like this is a high-quality experience (no sloppy messages), yet we’re friendly and excited about the artwork too. For instance, after generating previews, in the empty area or header we might say: “Click a style to see your art come alive!”[13] – reinforcing that interactive, magical feeling.

4. Instant Preview Strategy
We will implement an “instant preview” pipeline where the user gets one AI-generated preview as quickly as possible, then additional variations shortly after. Specifically, after the photo upload, the system will immediately generate the first style preview, and then progressively fill in 2-3 more preview slots in the background.

Fast First Preview: As soon as the image is uploaded (and cropped/oriented as needed), we’ll trigger a preview generation for the top recommended style without waiting for user input. The “IntelligentStyleGrid” already identifies recommended styles after analyzing the photo[14][15]. We will take the first style in that recommended list and call the generation function on it straight away. This means likely calling our generateAndWatermarkPreview utility for that style id as soon as analysis is done (or even in parallel with analysis, if we trust orientation defaults). The result: within a few seconds, the user will see their photo transformed. This first preview will be intentionally quick – we can pass a “preview” quality parameter to generate a medium-res version faster if supported[16]. The server-side is built to return either an immediate URL or a requestId for polling[17]; our client hook useStylePreview already handles polling until ready[18][19]. We will leverage that to update the UI as soon as the preview URL is available.

Progressive Additional Previews: While the user is looking at the first preview, we’ll start generating a couple more style variants in the background. For example, we might choose the next two recommended styles from the list and call the generation for those as well (one after the other, to avoid overloading the edge function). As each completes, it will appear in the UI – either as another preview card or an image replacing a placeholder in the style list. The idea is that within, say, 5–10 seconds the user could have 3 different styled previews of their photo to explore. This showcases variety and encourages them to click through different looks (in case the first style wasn’t exactly what they envisioned). It also increases the chance at least one preview will really “wow” them.

We have to manage concurrency carefully: our edge function and Replicate have a cost, so we won’t generate all styles (that could be dozens) without user action. We’ll limit to a small handful (the most relevant ones). We’ll implement a queue such that if the user quickly selects a different style, we prioritize that generation and possibly cancel any not-yet-started background ones.

UI for Previews: The style selection grid will show placeholders for the previews being generated. For example, we might display each style’s thumbnail image (from the artStyles metadata) with a subtle overlay and a spinner icon, indicating “preview loading.” Once the preview is ready, it will fade in, watermark and all. The first preview might also be shown in a larger highlight (perhaps as the main canvas in studio view). We will visually highlight the currently selected style – likely by a border or glow around its card. (The code already sets isSelected for style cards and applies a ring style on the “Continue” button[20]; we can extend that to the card appearance itself). For example, the selected style card can get a purple border and maybe a checkmark in the corner for clarity.

Placeholders & Transitions: Each preview card will have a skeleton state. This could be a simple gray skeleton with a shimmering effect, or a blurred version of the style’s sample image. A nice touch: use the style’s base color palette to create a fuzzy preview background, giving a hint of what’s coming. For transitions, we’ll use a quick fade-in (200–300ms ease-out) when the real preview image loads, so it feels smooth. The placeholders themselves can fade out simultaneously. This avoids jarring pops of content.

When the first preview is ready, if we are in a dedicated Step 1 view, we might automatically advance the UI to show the preview prominently. In the Hybrid model, we might simply show it in the canvas area and perhaps even auto-expand into the studio mode once it’s ready (because at that point Step 1 is effectively complete). If auto-advance feels too sudden, we will at least enable the “Continue” button instantly with a pulse animation to draw attention to it.

Handling Long Generation Times: Our target is to have the first preview in just a few seconds (with caching, often it might be near-instant[21] if an image/style combo was generated before and stored). But if a generation takes longer than ~10 seconds, we’ll employ a fallback: - We will not block the user’s entire session waiting. If the first preview is slow, we’ll display a message like “Still working on it – you can continue exploring options and we’ll pop in your art shortly!”. In practice, since style previews are central to decision-making, we expect users might wait, but at least they won’t feel forgotten. We might show a small “Generating preview in background…” toast and allow them to try another style if they want (with the understanding that whichever returns first will show up). - If a user switches styles while the first is still generating, we’ll start that new style’s generation immediately. The system (via React Query or similar) can cancel the previous request or simply let it finish and cache the result without showing it if the user has moved on. - In extreme cases (server down or taking 30+ sec), we will show a graceful error state: e.g., “This style is sleeping. Try again or choose a different style.” with a retry button (the code sets validationError on errors[22] which we can surface as an alert banner near the style).

Concurrency & Caching Notes: The architecture is set up to avoid duplicate work – e.g., if a preview is requested and then the same request comes again, the edge function likely caches it, and our usePreviewGeneration should serve from cache when possible[23]. We will ensure to funnel all preview generations through the existing hooks so caching isn’t bypassed. That means using the single source in usePreviewGeneration or context, rather than calling the API directly from multiple places. For instance, if background generation A is still polling and user triggers generation B, both will update the same context store of previews once ready. We’ll also maintain that changing orientation resets previews (as it does now to avoid mismatches[24]).

In summary, the first preview will hit the user almost immediately – likely a lower-res watermarked image to wow them – and additional previews will then slide in, showing off alternatives. All the while, the user can interact (select a style, recrop, etc.) without feeling locked out. This approach keeps the user engaged during any waiting period and maximizes the chance they’ll see something they love, fast.

5. Visual Language & CSS System
We will establish a cohesive visual design system using Tailwind CSS tokens and utility classes, ensuring consistency across the app. Below is a proposed design token set and key component styles reflecting Wondertone’s brand:

Color Palette: Wondertone’s brand uses a vibrant tech-inspired palette. We’ll formalize it as: - Brand Primary: A rich purple (e.g. Tailwind purple-600 as base). This is used in gradients and emphasis text. It conveys the “magic” tech vibe. - Brand Secondary: A hot pink (e.g. pink-500) and a cyan/blue (e.g. cyan-500 or blue-600). These appear in our gradients and accents. For instance, our primary CTAs often go from purple to pink or purple to blue in a gradient[25]. We will continue using these multi-color gradients for a modern, premium feel. - Neutrals: Rely on a neutral gray scale for backgrounds and text: e.g., gray-50 for page background, gray-100/200 for card backgrounds, gray-700 for body text, gray-900 for headings. We’ll ensure text contrast is sufficient – e.g., the body text currently often uses text-gray-600[26] which is fine (about 5:1 contrast on white). - States: - Success/Confirmation: Emerald/Green (e.g. emerald-500). We use this for “Continue” buttons and success messages. For example, the “Continue with This Style” button is a green gradient[27] and the toast for watermark removal success uses green styling[28]. - Error/Danger: Red (e.g. red-600). Used for error messages, the “Try Again” outline button, and error badges. We see red in the “Watermarked” label on previews[29] and error toasts[30]. - Warning: Orange/Amber (e.g. orange-500) for caution messages or icons (for instance, an orange icon is used for video length slider marker[31]). This would be rarely used, but available for things like “slow down” notices or important tips. - Info: Blue (e.g. blue-600) for informational highlights. We use blue for trust icons (truck icon for shipping[32]) and the voice-match badge background[33]. Blue implies reliability (good for subtle info messages or links).

All these colors will be available as CSS variables or Tailwind classes. We’ll derive hover and active states from them (usually one shade darker on hover, as we already do in gradients[25]).

Typography: We’ll use Inter for UI text and Poppins for display headings, as per brand guidance. Concretely: - Body/Base font: Inter, sans-serif. We’ll keep the base text at 1rem (16px) with a comfortable line-height (~1.6). This is for most labels, instructions, and button text (except where we intentionally use display font). - Headings/Display: Poppins, sans-serif, for a bit of artistic flair in big text. We’ll define a type scale, for example: - text-4xl (maybe ~36px) for hero headlines or section titles (e.g., landing page h1 might use this with Poppins – giving a friendly, round feel). - text-2xl (~24px) for subheaders or step titles. - text-lg (~18px) for important labels or card titles. - Smaller sizes (14px, 12px) for supporting text, captions, and fine print. We saw instances of text-sm used for descriptions[34] and text-xs for badges[35]; we’ll continue that pattern. - Font Weight & Spacing: We’ll use semi-bold (600) or bold (700) for important text (buttons, headings) to ensure legibility. For example, headings in Poppins can be bold for a clean, geometric look. Inter can be medium for button labels. We already see bold used in places like card titles[36]. Letter-spacing generally normal, except for all-caps or decorative pieces. (We use some tracking-wide on small uppercase text like processingStage captions[37] – that’s fine for those niche uses.) - We’ll ensure a consistent font usage: e.g., all buttons and nav use Inter (for clarity), whereas marketing slogans or the product name in hero could use Poppins.

Sizing & Spacing: We will stick to a 4px grid (Tailwind’s spacing increments). So: - Base unit: 4px. We use multiples for padding/margins: e.g., .p-4 (16px) is common for card padding[38], .px-6 .py-3 for buttons gives roughly 24px x 12px which feels balanced. - We’ll define spacing tokens like small (4px), medium (8px), large (16px), XL (24px) in our design documentation for consistency. In code, that corresponds to .m-1, .m-2, .m-4, .m-6 etc. The UI already uses space-y-6 or 8 often[39][40] – meaning ~24px gaps, which we will maintain for section separation.

Borders & Rounding: The interface uses rounded corners liberally to convey a modern, friendly feel: - We’ll standardize border radius: use rounded-xl (~0.75rem or 12px) for cards and modals (as seen on upload dropzone, which has rounded-2xl in some places for an even larger radius[41]). We can use rounded-lg (8px) for smaller elements like buttons or input fields, so they are slightly pill-shaped but not overly round. - We have instances of fully rounded elements (e.g., small icons in circles, or the pulse dot indicating QR code scanning[42]). For those, we use rounded-full (50%). - Borders: We use hairline borders (1px) for subtle divides – e.g., the light gray border around cards or form fields (Tailwind border-gray-200 as seen on container edges[43]). For interactive focus or selection, we sometimes use thicker borders: e.g., the Living Memory card when enabled uses a left border 4px purple[44] to highlight it. We will continue that convention: 4px accent border to mark selected state or on-focus of important cards (it’s a clear visual indicator). - Dashed borders are used in the upload dropzone for a decorative effect[41]. We’ll keep that as is – it gives a creative vibe. For most other components, solid borders will do.

Shadows & Elevation: We want to communicate depth for modals, pop-ups, and active elements: - Use Tailwind’s shadow-lg and shadow-2xl for cards and modals respectively. The upload card already uses shadow-2xl for a pronounced elevation[45]. We’ll ensure modals (like dialogs for token purchase or watermark removal) have a strong drop shadow with maybe slight blur for a soft look. - We can incorporate subtle colored shadows on hover for interactive delight (the code uses a cyan/purple shadow on hover of dropzone[46] and buttons). For instance, primary buttons might get a faint glow of the same hue when hovered (hover:shadow-xl). We will use a base shadow color (neutral black at 10-20% opacity) for general use, and strategic colored shadows (purple/blue) for special hover states or emphasis backgrounds to align with the neon-esque aesthetic. - Elevation scale: no shadow (flat) for base elements, shadow-sm for input fields if needed, shadow-md for raised buttons, shadow-lg for cards/menus, and shadow-2xl for modals and the header on scroll. We’ll avoid any heavy drop shadows that cause high CLS; these are purely cosmetic and not shifting layout.

Motion & Interaction: We’ll follow a motion guideline that feels smooth but not distracting: - Base transition duration: ~200ms for most hovers and state changes. For example, button hover color transitions and scale are ~0.2–0.3s currently[47]. We’ll standardize at 250ms ease-out for fades and color changes, which gives a nice quick response. - Entrance/Exit: For modals or large elements appearing, we might use 300–350ms with an ease-in-out curve, possibly with slight overshoot (e.g., a spring effect on a success checkmark icon popping in). But we’ll keep it subtle to maintain a premium feel (no cartoonish bounces). - We will use Tailwind’s built-in easing classes or custom cubic-bezier for gentle motion. For example, transition-all ease-out duration-300 is already common in our classes[48] – we will apply similar to component state changes. - Hover effects: We’ll maintain the nice scale-up on hover for buttons and cards (a subtle 2% enlarge and upward translate[47]) to convey interactivity. We must ensure this is disabled or reduced on devices that don’t use hover (tailwind can conditionally apply on hover only for pointer devices). - Focus states: We will use a combination of outline or ring to show focus for keyboard navigation. For example, we can use focus:ring-2 focus:ring-purple-500 on focusable elements, ensuring even custom components like the style cards show a visible outline when tabbed to. - Reduced Motion: We respect prefers-reduced-motion. In CSS, we’ll add @media (prefers-reduced-motion: reduce) rules to disable non-essential animations (e.g., turn off the hover scale/translate and just change color, or remove the infinite pulse animations on decorative elements). This way, users who opt out of motion get a simpler experience. For instance, the floating glow background in the upload card can be static if motion-reduced is on[49]. - Micro-interactions: We’ll incorporate small delightful animations, like the QR scan dot pulsing (already implemented[42]). Another example: when the user toggles the Living Memory switch on, we could briefly animate the price badge or icon (maybe a faint glow to draw attention to the new feature and its cost). These will be done with ~200–300ms transitions or keyframes.

Component Style Guide:

Primary Button: Used for main calls-to-action (e.g. “Start Creating”, “Order Now”). Styles: full gradient background, rounded, with white text. For example, a class combination: bg-gradient-to-r from-purple-600 to-blue-600 text-white font-semibold py-3 px-6 rounded-lg shadow-md hover:shadow-lg hover:from-purple-700 hover:to-blue-700 transition-transform duration-200 ease-out hover:-translate-y-0.5 hover:scale-105 focus:outline-none focus:ring-2 focus:ring-purple-500. (This is inspired by current buttons[25] and will produce a vibrant button that slightly “lifts” on hover). On mobile, it will be full-width if needed; on desktop, auto width or fixed as design dictates.
Secondary Button: Used for less prominent actions (e.g. “Cancel”, “Back to Edit”). Styles: outline or subtle fill. We’ll often use a white or light gray background with a gray border. For example: bg-white border border-gray-300 text-gray-700 font-medium py-2.5 px-5 rounded-lg hover:bg-gray-50 hover:border-gray-400 focus:outline-none focus:ring-2 focus:ring-gray-400. This gives a clean, unobtrusive look. We already see outline buttons like the retry one using similar styling[50] (text red on hover of red outline) – we’ll adapt the color to context (gray default, or red for dangerous actions).
Style “Chips” / Tags: If we have small selectable chips (perhaps for orientation or style categories), they will be pill-shaped with subtle backgrounds. E.g., a tag might be text-xs font-medium px-3 py-1.5 rounded-full bg-gray-100 text-gray-800 for a default tag. If selectable, on select it might change to bg-purple-100 text-purple-800 to denote activation. These would use Inter for readability at small size. (An example use: the “Most Popular” badge in token packs is essentially a chip with text-white on blue[51], which we’ll continue for labeling things as popular or favorite).
Cards-/-Tiles (Style Previews & Product Cards): Our card components will have a white or light backdrop, rounded corners, and subtle shadow. For style preview tiles specifically: they contain an image plus maybe a title. We’ll use rounded-xl overflow-hidden border-2 border-gray-200 hover:border-purple-300 transition on the card wrapper. When a style preview is generated, the card will show the watermarked image filling it (with object-cover). If a style is selected, we switch the border to brand color (purple or green) and perhaps add a check icon overlay. For example, the selected style card might get border-purple-500 ring-1 ring-purple-300 to stand out. Non-selected have just a hover border change. All cards get a slight lift on hover thanks to the shadow and transform: e.g., hover:shadow-xl hover:-translate-y-1 for desktop hover. (We see something similar on LivingMemoryCard hover using group hover classes[44]).
Bottom Action Bar: This will be a fixed container at the bottom, full-width. Style: bg-white border-t border-gray-200 shadow-lg (to ensure it’s elevated above content)[43]. Inside, we have a responsive layout: on mobile, show a small summary of total and a large primary button; on desktop, include maybe some trust icons and the button with more padding[52][53]. We’ll use a bit of padding (e.g., .p-3 sm:p-4) and ensure text is legible (likely Inter, md size). The “Order Now” button inside will be a primary button style (purple gradient) but slightly smaller if needed to fit. We see an implementation already: the StickyOrderCTA in code uses exactly these styles (text-xs for label, text-lg for total, etc.)[2][53] – we will adopt that as our base and adjust if necessary for consistency with our main buttons (making sure the colors match our updated palette choices).
Toggles (Switches): For binary options like the “Living Memory” AR toggle, we use a switch component. Our style: when off, the switch track is gray (e.g., bg-gray-200), and the thumb is white. When on, the track is filled with a gradient or solid brand color (e.g., purple), and the thumb is also brand-colored or white depending on design. The code from shadcn’s Switch likely already handles this with a data-[state=checked]:bg-purple-500 class on the track[54]. We’ll ensure the thumb has a slight shadow for depth. The size should be large enough to tap (about 40px wide track). We’ll accompany toggles with clear labels. In the LivingMemoryCard, for example, the label “Living Memory AR Experience” is to the left and the Switch to the right[55] – that’s good. We might enlarge the icon inside the thumb or track if needed to indicate state (some designs show a check or cross, but probably not needed here).
Badges: Small inline badges for highlights (e.g., “Customer Favorite”, “Most Popular”). Style: rounded pill shape, small text. We use either solid background for important ones or outline for subtle:
Solid example: the price badge “$59.99” in the Living Memory card uses bg-purple-100 text-purple-700 font-semibold px-2 py-1 text-xs rounded[56]. We will use that pattern for price badges or status: light background of the relevant color and darker text.
Outline example: “Customer Favorite” uses variant outline (pink outline)[57]. That is basically text-pink-600 bg-pink-50 border border-pink-200 rounded text-xs px-2 py-1. We’ll maintain an outline variant in our badge component classes.
All badges: use a tight font (Inter or Poppins medium) and uppercase or title-case. We keep them small so they don’t dominate but provide quick info.
Toasts & Notifications: Our toast style will follow the shadcn UI defaults with slight customization. Generally a toast is a small card with a shadow. We’ll make success toasts green-tinted (e.g., success toast could have a green icon and maybe a subtle green border on the left), error toasts red-tinted (or use the “destructive” variant as in code[30]). For instance: border-l-4 border-green-600 bg-white shadow-md rounded px-4 py-3 text-gray-800 for success. We won’t overdo styling here – consistency and visibility are key. Toast text will be Inter, and we’ll include an icon (check for success, alert triangle for error) for easy scanning.
Progress Rings/Indicators: If needed (perhaps if we show a circular progress for generation), we’ll design a simple circular ring using SVG. E.g., a ring with purple stroke that animates dashoffset. But since our strategy uses mostly linear spinners and the “magic sparkles” icon for progress, we might not need a circular progress component yet. However, if implementing one for say AR video upload or similar in future, we’d style it with brand color track and a faint gray background track. It would appear next to the relevant item (maybe overlayed on the preview image). Duration of spin one cycle maybe 1s linear if indeterminate.
Motion Preferences: As noted, base motions ~200ms ease-out. We’ll choose a spring for certain elements like drag-and-drop interactions or momentum feeling in carousels (if any). For example, when the preview images load, we could use a tiny spring so they “pop” in. But we will ensure prefers-reduced-motion disables these extras. Keyframes like animate-glow-pulse on icons (we have one for the AR badge pulse[42]) will be paused under reduced-motion preferences.

By defining these tokens and class patterns, we create a vocabulary the devs and designers can share. For instance, “Primary button” always means the purple-gradient large button with those Tailwind classes, ensuring all CTAs look alike. This makes the UI feel consistent and polished, reinforcing user trust. We will document these recipes (perhaps in a Storybook or a style MD file) so any new component can follow the system.

6. “Living Canvas” AR Add-On Placement & Demo
The “Living Memory” QR-video add-on (where a canvas can play an AR video when scanned) will be introduced prominently during the customization phase, with a persuasive preview and clear pricing. We will integrate it at two points in the user journey:

In the Customize Step (Primary): Within the studio’s customization panel (formerly step 3), we’ll have a dedicated card for the AR add-on – effectively the LivingMemoryCard (which already exists)[58][55]. This card appears alongside other add-ons like frame and AI upscale. We will ensure it’s high in the list (likely right after frame selection) so that users see it while configuring their canvas. The card will contain: - A title and brief description: e.g., ““Living Memory” AR Experience – Transform your canvas into a video memory” (the card already says “magical living memory with cutting-edge AR”[34] which is great). - A price badge: clearly showing $59.99[35] (so users know it’s a premium option). - A toggle switch: to add or remove the feature[54]. The switch is off by default. - A micro demo/visual: This is crucial. We propose adding a tiny phone-shaped graphic or video within the card to demonstrate the feature. For example, we can show an icon of a smartphone with a play icon or a short looping video clip on its screen to simulate scanning the canvas. One idea: use a 5–6 second loop of a real example – perhaps a bride’s portrait on the canvas turning into a short video clip of the wedding moment. This could be displayed within an image of a phone for context. We might repurpose assets from the marketing site; e.g., the InteractiveDemo/ARPreview components show a QR and mention scanning[59][60]. We can leverage a static graphic from there. This visual demo will draw attention and help users instantly “get” what the AR does, overcoming any confusion. - Copy Tone: We keep it enthusiastic but brief. We’ll retain the current wording and add a line emphasizing ease: e.g., “🎥 Point your phone at the canvas and watch it come alive – no app required!”. This addresses potential concern (scanning via normal camera is enough) and reinforces the wow factor[61]. The LivingMemoryCard already includes a line with a camera emoji stating point and watch memories come alive[62] – perfect, we’ll keep that.

When the user toggles this option on, we may show a sub-section (already implemented as PremiumVideoOptions panel) where they can configure extras like voice or background music[63][64]. That panel only appears if livingMemoryEnabled is true[65]. We will surface it as an expandable section beneath the main card, labeled maybe “Customize AR Video (optional)”. This way hardcore users can add voice matching etc., but casual users can ignore it if they don’t expand. We’ll indicate any additional costs clearly (the PremiumVideoOptions UI already lists +$ prices for each enhancement[66][67]).

In the Review/Cart (Secondary Upsell): We will also provide a gentle reminder about the AR add-on in the final review stage if the user did not opt for it. For example, on the Order Summary page or as a popup before checkout, we can say “Enhance your canvas with a Living Memory video?” with a last-chance toggle. Concretely, in the OrderItemsList or PricingBreakdown, if livingMemory is false, we can insert a small banner: “🌟 Make it unforgettable: add AR video for $59.99” and an “Add to Order” button. Clicking that would toggle the option on (we’d update state and pricing immediately – since we’re still on the confirmation step). Because adding it at the last second changes the total, we need to recalc totals (which our state can handle) and update the summary UI. This upsell should be noticeable but not annoying – perhaps a bordered prompt below the item list. We’ll track how many users add at this stage via an analytics event qr_added (with stage: review in payload if we want).

Demo Micro-UI Implementation: For the tiny phone demo within the customization step: - We’ll include an image of a smartphone (perhaps a simplified vector) with a short video snippet superimposed. This could be implemented either as a small <video> element playing on loop, or an animated GIF inside the phone screen area. We might prepare a 5-second clip of an example AR video (with permission) to use here. - This visual will be small (maybe 100px tall on mobile, 150-200px on desktop) and should not overly distract from the form. It will serve to visually explain “phone + canvas = video playback”. - If technical constraints prevent video in the UI (to avoid loading issues), we can use a static image showing a QR code being scanned with a play icon. But a looping video is much more compelling. Perhaps we can reuse the approach from InteractiveDemo which had a QR code and indicated scanning[59]. We might even allow the user to scan that demo QR with their own phone to see a sample – that’s an idea: a “See Live Demo” link that opens the AR demo (like a modal with the actual QR code as in the marketing site). - Copy to accompany the demo: The LivingMemoryCard currently mentions “Customer Favorite” on a badge – we will keep that to nudge social proof[57]. We may add a tiny “Learn more” link on the card, which when clicked triggers qr_viewed event and perhaps pops up an explanation modal (could embed the same content as the AR section of the marketing page, e.g., testimonials or a short video of someone scanning a canvas). If time allows, we’ll implement this modal; if not, the inline demo image should suffice.

Pricing Display: We will always be transparent about the price of the AR add-on: - On the customization card, the badge $59.99 is shown upfront[35]. If the user toggles it, the PricingSummary updates to include +$59.99 under add-ons (we already compute livingMemoryPrice = 59.99 in state[68]). - If voiceMatch is chosen, that adds $19.99, and our pricing breakdown adds that too[68]. We will label these line items clearly, e.g., “AR Video Add-On: $59.99” and “Voice Matching: $19.99”. The OrderItemsList can list them as separate add-ons under the product entry (and we ensure the total reflects them). - In the final total section, shipping is calculated and free over $75[69], so notably adding AR often pushes the order over that threshold – we might even subtly highlight “Free Shipping unlocked” if their subtotal crosses $75 due to AR, as a positive reinforcement.

Event Tracking: We will instrument: - qr_viewed: Fire when a user actively engages with learning about AR. This could be when they click the “Learn more about Living Memory” link or expand the PremiumVideoOptions. It signifies interest. Payload can include stage (whether at customization or review). - qr_added: Fire the moment the user toggles Living Memory on (enabled). We capture maybe voiceMatch: true/false if they also selected that, or just note that they added the AR feature. One place to hook this is in the onEnabledChange of LivingMemoryCard component – when enabled flips to true[70], call our analytics. Another is if they add via the review upsell, fire it there.

These events let us measure what % of users consider or purchase the AR add-on, and at what point.

By surfacing the AR feature at customization and again at review (if not taken), we maximize its visibility without being overbearing. It’s presented as a natural extension of the product (“Make your art a Living Memory”), rather than a random upsell at checkout. The combination of a compelling visual demo, clear benefits (“watch memories come alive”), and trust signals (“customer favorite”) should drive a healthy uptake of this $59.99 add-on.

7. Demote & Refine the “Token Download” Path
Currently, users can purchase tokens to download their AI art without watermarks (digital-only path). We will relegate this option to a secondary, non-disruptive position in the UI, ensuring the primary flow focuses on buying a canvas. The goal is to still allow enthusiastic users to get digital copies, but to prevent casual users from veering off the purchase funnel early.

UI Changes: In the style selection step (where the previews are shown), we will transform the “Remove Watermark & Download” button into a much more subtle action: - Instead of a large green full-width button of equal weight to “Continue with This Style”[27][4], it will become a small text link or an icon-only button. For example, beneath or beside the “Continue” button, we might put: “Download image (no watermark)” in a smaller font. It could be styled as a tertiary link – gray text with an inline download icon (🔽). - Another approach: have a single button with a dropdown or menu. The primary button could be “Continue (Buy Canvas)” and a split-button or smaller adjacent button could say “... or Download Image”. But to keep it simple, a lone link is fine. - We will add clarifying text to this link: e.g., “Download HD Image” with a tooltip on hover: “Receive a high-res digital file without watermark (uses tokens)”, so users understand it’s a paid download. The word “tokens” might be jargon for new users, so maybe the tooltip or modal explains pricing (the token packages modal already lists rates and is invoked when needed[71][72]). - By downplaying this option, users’ eyes will naturally gravitate to the bright “Continue” button for the physical product, which is what we want.

Flow Adjustments: If a user does click the download link, we will handle it as follows: - Open the WatermarkRemovalModal (as currently implemented)[73], but it should feel like a side-quest, not the main path. The modal lets them choose resolution and spend tokens[74][75]. We will ensure that closing the modal returns them right back to where they were in the configurator. - We’ll potentially add a gentle reminder in that modal like “Prefer a museum-quality canvas print? You can always order a canvas instead.” as a footer, just to keep the canvas option in their mind. - If they proceed with purchasing a download (token flow), fine – they’ll get their image. After downloading, the UI will show that style as “Downloaded” (the code already tracks existingPurchase and shows a “Re-download” button if they’ve bought it[76]). We will not mark the configurator as complete though; they can still click “Continue with This Style” to buy a canvas if they choose. (Edge case: If someone downloads and then orders a canvas, they might wonder if the canvas will have watermark removed – it will, since we don’t print watermarks on purchased canvases by business logic). - In summary, the download path becomes an optional offshoot. It does not progress the step flow. The user remains on Step 1 (style selection) even if they download, until they either leave or continue to the canvas purchase.

No Collision with Purchase Flow: By not mixing the download with the main step progression, we avoid conflicts. For instance, currently if a user clicked “Download” instead of Continue, they might never reach step 2. That’s acceptable – they got their digital file and might stop. This is effectively a conversion of a different kind (token sale). Our changes won’t break that; we’re just not shining a big spotlight on it early. The physical purchase flow (steps 2–4) remains intact and is now the obvious “next step” in the UI.

We will double-check routing: the /product page can handle both outcomes (the state might already track purchases via useDownloadPurchases hook[77] to disable the download button once used). We don’t need a separate route for downloads; it’s all on the same page modals. So no new routing complexity introduced.

Messaging: To ensure clarity: - We will rename “Remove Watermark & Download” to something more user-friendly like “Buy Digital Copy”. The term “remove watermark” is a bit technical; “Digital Copy” tells them what they get. The UI text could be “Buy Digital Copy (from $4.99)” – if we want to hint price – but since tokens vary, maybe not. We could just say “Download Image” and when they click, the modal explains token cost (which it does: it lists tokens needed per resolution[78]). - We will make sure the watermark on the preview image itself (the red “Watermarked” badge on the corner[29]) remains visible, so it’s clear to the user that the preview isn’t final quality. This subtly nudges them that to get a clean image, they either buy a canvas or use the download option.

State & Analytics: We will monitor usage of this path. In analytics, we’ll track an event like download_clicked whenever someone uses the download link, and download_purchase when they successfully download (with resolution and tokens spent). This is secondary to our main funnel metrics but good to know if demoting it significantly impacts usage (could be intended if those users shift to canvas purchase instead). - We’ll ensure the demotion doesn’t accidentally hide it from those who really want it. For instance, on mobile, a small link might be easy to miss. We might instead use an icon button with a downward arrow and tooltip “Download”, placed at the bottom of the style card. That way, it’s present but not shouting. On desktop the tooltip can clarify cost. - The token purchase modal and balance display (in header) remain for power users. We won’t remove those. The header has a token balance icon when logged in[79] – that’s fine to keep; it doesn’t distract new users much.

By doing this, the default narrative for new users becomes: upload photo → see cool previews → “Continue” to buy a canvas. Only if they explicitly look for a download (or know about it from somewhere) will they find that smaller option. This should increase the focus on the physical product path. We are effectively changing the priority, not removing a feature. And importantly, we are not breaking any logic around token purchases. All that backend (Supabase function for remove-watermark, etc.) stays the same[80]. We’re just altering the call UI.

One more small refinement: in the final checkout or success page, we might mention to the user who only did a download: “Enjoy your artwork! You can find your download in your account.” And maybe prompt them to create an account if they were guest so they don’t lose it (since an unregistered user who buys tokens is actually forced to log in by our current flow, so that might not happen as guest anyway). In any case, those details can be handled in the auth flow.

In conclusion, canvas purchase becomes the star of the show, while the token download becomes a footnote – readily accessible to those who need it, but not pulling others away from a higher-value sale.

8. Analytics & Experimentation Plan
To measure the impact of our changes and continue optimizing, we’ll implement a robust analytics schema and at least one A/B test.

Event Tracking Plan: We will instrument the following key events (with suggested payload details):

upload_started – Fires when a user initiates an image upload. Payload: { timestamp, file_size, file_type, source: 'heroCTA' | 'dragdrop' }. This marks the beginning of the funnel. We’ll capture the time (for later calculating preview latency) and maybe how they uploaded (clicked button vs drag-and-drop).
first_preview_ready – Fires when the first AI preview image is rendered to the user. Payload: { timestamp, style_id, time_since_upload_ms }. We calculate the difference between this and the prior upload_started to measure our KPI. Also log which style was shown first (to see if certain styles are more often the “first wow”).
additional_preview_ready – Fires for each additional preview that loads after the first. Payload: { style_id, time_since_upload_ms }. This helps gauge how many previews users see and how fast. If we generate 3 by default, we expect up to 2 of these events typically. We can see if users wait for them or proceed after the first.
style_selected – Fires when the user selects a style to proceed with. This corresponds to clicking “Continue with This Style” or using the chosen style in the next step. Payload: { style_id, style_name, was_recommended: boolean, time_since_upload_ms }. We can determine if users often go with the first recommended style or if they click through several. The timestamp helps see how long they deliberated.
entered_customize – Fires when the user enters the customization phase (step 2 in old flow, or when the studio screen loads size/frame options). Payload: { timestamp, style_id }. Essentially when currentStep changes to 2 (or when they complete step1). We want to measure funnel drop-off between preview and customization.
size_selected – (If relevant) Fires when user selects a canvas size. Payload: { size_label: '8x10' | '12x16' | ... }. This might be granular, but could be useful to see which size is most popular and if users change sizes.
frame_toggled – Fires when user toggles the floating frame option. Payload: { frame_color: 'black' | 'white' | 'espresso' | 'none' }. This captures upsell of frame and preference.
qr_viewed – Fires when user views more info about the AR add-on. As discussed, perhaps when they click a “Learn More” or when the AR demo modal is shown. Payload: { stage: 'customize' | 'review' } to know where they considered it.
qr_added – Fires when the user adds the AR “Living Memory” to their order (toggle on). Payload: { voiceMatch: boolean, videoLength: seconds } – basically any specifics chosen, and stage if added in review. This event marks a high-value upsell conversion.
add_to_cart – Fires when the user adds the configured canvas to cart or proceeds to checkout. Since our flow is immediate checkout, this would be when they hit the “Order Now” button (which either opens payment form or stripe checkout session). Payload: { timestamp, cart_value: number }. It signals intent to buy. If we have a multi-step checkout, we’d fire at beginning of checkout.
checkout_started – Fires when the actual payment process starts. If using Stripe Checkout, this could be when we redirect to Stripe or when PaymentForm is submitted. If on-site payment, perhaps when the user submits their address and goes to payment step (though our OrderSummary includes PaymentForm inline[81], we could fire when they focus on payment or when they click “Place Order”). Payload: { method: 'stripe_card' | 'apple_pay' | ... } if available, and total }.
purchase – Fires on purchase completion (order confirmation page load, or webhook callback if needed). Payload: { order_id, total, items: [ { size, frame, livingMemory } ], tokens_used: number(optional) }. This is the ultimate conversion event for a canvas purchase. We will also consider a separate event if they only bought a download: maybe download_purchase event, with tokens spent. But the main one is canvas purchase.
We will utilize these events to compute our north-star KPI (“time from upload to first preview”) and monitor conversion at each stage. For example, funnel analysis: of 100 upload_started, how many first_preview_ready, how many style_selected, how many purchase, etc. Time metrics will confirm if our speed improvements hold (e.g., median time_to_preview ideally under, say, 5000ms).

We’ll implement events likely using the Supabase analytics (if available via a logging table or using something like PostHog or GA). We’ll ensure not to double-count (each event fires once at appropriate trigger).

A/B Test Proposal: Test #1: Style Preview Layout – Grid vs. Carousel

Hypothesis: Presenting style options in different layouts may affect how quickly or decisively users pick a style (and ultimately convert). We suspect that a carousel (showing one large style preview at a time with the ability to swipe/next) might lead users to focus and be wowed by each style, potentially increasing the chance they see a style they love (but it might slow them down slightly). A grid (many smaller previews at once) lets them compare at a glance and might lead to faster decisions but could be overwhelming.

Experiment Design: We will split new users into two groups upon reaching style selection: - Variant A: Grid Layout (the control, essentially our planned design). The IntelligentStyleGrid shows, say, 6 style cards on screen (2 rows of 3, with hero recommendations highlighted)[15]. Each card is medium size and user can scroll to see more. - Variant B: Carousel Layout. Instead of a full grid, user sees a large single preview (maybe the recommended style first) taking most of the canvas area, with a swipe or “next style” arrow to cycle through other style previews. Thumbnails might be small dots or a horizontal strip below.

We’ll keep everything else consistent (auto-generation of previews, same styles offered). The difference is the interaction pattern and how many previews are visible concurrently.

Metrics: Primary metric – time to style_selected. We predict that in Carousel (B), users may take longer to cycle through, so time_to_select might be higher but perhaps they will be more confident in their choice. In Grid (A), time_to_select might be lower (they see all and pick one quickly). We also track conversion to purchase. It’s possible one layout yields higher final purchase rate. For example, maybe the carousel’s immersive focus leads to slightly more purchases (because they really got to appreciate a style full-screen), even if slower.

We’ll also measure number of styles previewed per user. In grid, a user might click 2-3 styles out of curiosity. In carousel, they might flip through, say, 5 styles because it’s easy to keep hitting next. If too many, that could indicate decision paralysis; if just enough, it means they engaged more deeply. This metric could inform which UX leads to “over-choice” vs. satisfaction.

Sample Size & Duration: We want statistically significant results on conversion, which is the lowest-frequency event (~purchase). Suppose baseline purchase rate is X%. To detect a meaningful uplift (or decline) of, say, 10% relative, we might need a few hundred conversions per group. If our traffic is moderate, we might run the test for 2-4 weeks to accumulate this. Specifically, if 20% of uploads lead to purchase, and we want ~400 purchases per variant for significance, that’s ~2000 uploads per variant needed. We’ll adjust depending on actual traffic. We’ll use standard significance (95% CI) and power 80% for calculation.

During the test, we’ll monitor early signals like preview engagement and style choice diversity. If one variant clearly has issues (e.g., users not finding how to change style in carousel), we’ll know via events like style_selected drop.

Success Criteria: If one layout yields a statistically higher purchase conversion or significantly faster time_to_preview with no drop in conversion, that variant would be favored. For instance, if Grid leads to 20% faster style selection and equal purchases, we’d likely stick with grid (faster funnel). If Carousel leads to a higher conversion (even if slightly slower selection), we might consider switching to that or incorporating elements of it (maybe a hybrid where recommended styles are larger in a slider, and others in a grid below).

We’ll document and implement this test likely via a feature flag in code (e.g., use variant from a query param or remote config to choose which component to render for style selection).

Other test ideas for future: testing different copy on the hero CTA (“Upload Photo” vs “Create Your Art”), or testing the presence of the AR upsell in the cart stage (maybe half see the upsell in checkout, half don’t, to ensure it’s not hurting primary conversion). But initially, the style layout test will give us valuable insight into optimizing the crucial style selection step.

9. Performance & Accessibility Improvements
We have aggressive performance targets to meet: LCP under 2.5s on 4G and CLS < 0.1, while not increasing bundle size beyond the ~567 KB baseline[82]. We will undertake specific optimizations in code splitting, asset loading, and UI stability:

Bundle Size & Composition: First, we’ll analyze the bundle (using npm run build:analyze which generates stats) to identify big modules. Some known potential heavy parts: - Supabase JS: The client SDK can be chunky (including auth). We’ll ensure we only import what’s needed (currently we import the whole client in supabase.ts). We could lazy-load it for features that truly need it (like preview polling and watermark removal). For example, do not initialize Supabase until after the upload is done – initial render could skip loading auth/storage if possible. However, since preview generation calls Supabase Edge Functions from Step1, we likely need it early. So, might not split that. - Image Cropper library: If we’re using a third-party for cropping (likely yes, maybe something like react-easy-crop or similar inside PhotoCropper), that could add tens of KB. We will code-split the cropper. Specifically, do not include the cropping tool code in the initial bundle. In PhotoUploadContainer.tsx, we see it imports PhotoCropper at the top[83], meaning it’s bundled. We can change this to dynamic import when needed. Plan: when user clicks “Adjust Crop” (handleCustomizeCrop), then load the cropper component asynchronously. Implementation:

const [CropperModule, setCropperModule] = useState(null);
useEffect(()=> {
  if(showCropper && !CropperModule) {
     import('../PhotoCropper').then(mod => setCropperModule(mod.default));
  }
}, [showCropper]);
Render CropperModule via <Suspense> with fallback. This way, if most users accept auto-crop, they never pay the cost of the cropping library. - ThreeJS or heavy landing media: We have some components like ThreeDStorybookHero, but those might only load on specific routes. Ensure those are not in the main bundle if not needed. Given we have multiple pages (Home, Product, Styles pages), Vite by default might not code-split pages unless using dynamic import for routes. We might implement route-based code splitting explicitly using React Router’s lazy. For example, in our router, import the Product page lazily so that the marketing home doesn’t include the whole app. The code already hints at prefetch for /product route[84], so they do treat it as separate. We can double-check that the product flow code is not loading on the home page. - Dead code removal: Run npm run dead-code:check as mentioned in agents.md[85]. For instance, if there’s an old CanvasWatermarkService not used, remove it. Or any legacy components commented out. This prevents bundling unused modules. - Library trimming: If any library is used just for a small function (like date-fns for one format, or lodash), consider tree-shaking or using native alternatives. Example: If using moment.js (unlikely here), switch to lighter lib or dynamic import only where needed. - Tailwind and CSS: Tailwind purges unused CSS by default in production, so CSS size should be okay. We’ll ensure our new classes are not overly specific so as to avoid bloat.

After these changes, we’ll re-run bundle analyze to confirm we stay at or below ~567 KB for main chunk[82] (hopefully even reduce it by ~10-15% by lazy loading cropper and other heavy pieces).

Waterfall Optimization & LCP: The LCP element on the product page is likely the first generated preview image (or the upload card if no preview appears quickly). We want the LCP to be that preview image, ideally within ~2.5s on 4G. Steps: - Preload critical JS and fonts: Ensure our index.html or equivalent preloads the main chunk and any critical font (Inter/Poppins). If self-hosting fonts, use rel="preload" for WOFF2 files, or if using Google Fonts, consider inlining the CSS to avoid an extra redirect. - Reduce main-thread work: The initial page should not do heavy computations before showing content. The StepOneExperience analysis (which analyzes the image for recommendations) is done after upload, not on page load, so that’s fine. We will avoid any expensive synchronous JS on load. For example, if any polyfills or detection scripts are running early, consider deferring them. - Lazy-load below-the-fold content: On the home page, sections like testimonials, FAQ, etc., can be lazy-loaded or at least image-deferred. On the product page, we might lazy-load the AR demo component or other non-critical parts. Actually, Product.tsx may contain step 1 content which is primary. We’ll ensure that even within that, the non-immediate parts (like the SocialMomentum widgets or help popups) don’t slow down rendering. E.g., UnifiedSocialMomentumWidget and BottomMomentumPopup can perhaps be loaded after initial render via dynamic import (since they are nice-to-have nudges, not needed in first paint). - Images: Serve appropriately sized images and use loading="lazy" for images not immediately needed. For example, in the landing page hero or style showcase images that are below fold, we’ll add lazy. The main hero image, if any, should be optimized/compressed. Perhaps generate WebP versions for modern browsers. If our LCP is an image (like on a landing hero), we’ll consider inlining a tiny data URI preview or using CSS background-image with gradient to improve perceptual speed. - Connection re-use: We call Supabase functions for preview. We can hint the browser to preconnect to the Supabase domain on page load (e.g., add a <link rel="preconnect" href="https://<supabase-url>"> in head). This saves DNS/TLS time when we later call it for image gen. Similarly, preconnect to Stripe or any payment domain if we know the user will hit that (maybe on checkout page only). - Avoid render-blocking: Ensure any external scripts (like Stripe.js) are loaded asynchronously or deferred. Stripe.js (if using Elements) can be a big file (~200KB). We will only load it when user actually enters payment step. Possibly using Stripe’s lazy loader or injecting the script tag when needed. - Prefetching: The code already prefetches the product route and auth route on hover or so[84][86]. We will extend that concept: for example, once user reaches step 2, we can prefetch the PaymentSuccess page chunk (so that after payment, it loads near-instantly). But that’s a minor improvement.

CLS (Layout Stability): We aim for CLS < 0.1 (basically no unexpected shifts). Steps: - Ensure images have explicit width/height or aspect ratio placeholders. For instance, the canvas preview container should reserve space. The Customization screen uses aspect ratio from orientation to set the preview size[87][88] – that helps avoid jump when the image loads. We will verify that every image tag in the app has either width & height attributes or CSS that fixes its container size. E.g., the style cards could have a fixed height (like 150px) so that the grid doesn’t reflow when an image appears. - Avoid inserting DOM above existing content. E.g., the top progress indicator (SmartProgressIndicator) is always rendered but just shows content conditionally[89], which is good. We should avoid things like suddenly rendering a new banner that pushes content down. If we do show a banner (like the AR upsell in review), consider overlaying it or giving it reserved space. But since review summary is near bottom, adding a small panel might not affect above content. - Check the header: it’s fixed at top, so that’s fine (doesn’t push layout when showing). Mobile menu opening overlays content rather than shifts it. - Transitions: any UI that pops in should either use absolute positioning or smoothly animate height. For example, when expanding PremiumVideoOptions under LivingMemory, wrap it so it smoothly expands rather than instant drop (though that wouldn't count as CLS if it animates after user interaction, but we ensure initial load doesn’t push unexpectedly). - Font swap: ensure our web fonts use font-display: swap so text renders with a system font then swaps to Inter/Poppins without layout shift (Inter metrics are similar to default sans, so swap is usually fine). - We will run Lighthouse or Web Vitals extension after changes to confirm CLS stays low. We expect CLS largely under control given we will preload dimensions.

Other Performance Tweaks: - Use requestIdleCallback or timeouts to load non-critical scripts. For example, the “live activity feed” component (if it fetches recent orders) can wait a couple seconds after load to fetch data so as not to compete with preview generation. - The useCarouselAutoplay mention in guardrails suggests we have an auto-rotating carousel somewhere[90]. Ensure that uses requestAnimationFrame properly and stops when offscreen to not degrade performance.

Accessibility Improvements: - Tap targets: We’ll go through all interactive elements to ensure they meet recommended size (roughly 44px by 44px). Our buttons are sufficiently large by padding. The style cards are clickable; on mobile, we should ensure adequate margin between cards so they’re not too close. Toggles and small icons should have padding. E.g., the Switch component likely is fine size but if not, we’ll adjust CSS to enlarge the clickable area (maybe invisible padding). - Keyboard Navigation: We will test that one can tab through the interface logically. The natural DOM order should follow the visual order. If we introduce any custom keyboard handling (like arrow keys to move between style cards), we’ll add those enhancements carefully. But at minimum, each control should be focusable and have a visible focus ring. If any focus ring is missing (due to outline-none classes used in design), we add a focus style. E.g., the gradient buttons currently might not show default outline because of custom classes – we’ll add focus:outline-none focus:ring-2 focus:ring-purple-500 to restore focus indication. - Labels & ARIA: Ensure form inputs have labels or aria-label. The upload dropzone should announce itself to screen readers as a button – we can add aria-label="Upload photo" on it (since it’s a <div> acting as button). Likewise, the cropper and sliders should have aria descriptions (shadcn components likely handle some of this). - Color Contrast: Double-check text on colored backgrounds. E.g., white text on purple 600 is okay (purple-600 on white gives ~ AAA large text contrast). Purple on purple (like purple icon on purple background) is just decorative so okay. The light gray on white (text-gray-500 on white) for very small text might be borderline; we might bump those to gray-600 if needed for WCAG AA (we want at least 4.5:1 for normal text). For instance, the placeholder captions etc. – we can test with a contrast tool. We prefer to err on side of slightly darker if unclear. - ARIA Live for feedback: When previews load or error happens, we can use aria-live regions to inform screen reader users. E.g., if generation fails and an error message appears, mark that container role="alert" so it’s announced. Toasts from use-toast should have role="status" or alert depending on variant, likely handled by library. We’ll verify. - Motion sensitivity: We covered prefers-reduced-motion. All auto animations (carousel autoplay, background floats) should pause when user requests. Also avoid parallax or similar if it affects vestibular (I don’t think we have heavy parallax, but if any, we disable it under reduce-motion). - Focus management: When opening modals (token purchase, watermark removal), focus should move into the modal (the Dialog component from shadcn likely does trap focus). And when closing, return focus to the triggering element. We’ll test those flows to ensure no focus loss.

By addressing these points, we ensure that the improved UX doesn’t come at the cost of performance regressions or inaccessible design. Instead, the app will load quickly and be usable by a wide range of users. We will verify performance with a combination of lab tests (Lighthouse) and real-user monitoring if possible (Chrome Web Vitals). Our aim: first meaningful paint with at least the upload UI in ~1s on modern devices, first preview in ~2-3s on 4G, and absolutely minimal layout shift throughout.

10. Implementation Plan (Two Sprints)
We will implement the above in two focused sprints. Below is a breakdown of tasks for each sprint, including file-level pointers, code approach, and QA checks for each item:

Sprint 1 – Core UX Improvements (Focus on Preview Speed & Simplification)
1. Auto-Generate First Style Preview
- Files: src/components/product/components/IntelligentStyleGrid.tsx, src/components/product/hooks/usePhotoUploadState.ts, possibly useStylePreview.ts.
- Change: After the user’s photo is cropped and ready, trigger an immediate preview generation for the top recommended style. In IntelligentStyleGrid, after calling analyzeImageForRecommendations and obtaining recommendations[91], call the generation for recommendations[0] style. We may add a new hook or function usePreviewGeneration (if not existing) to handle this centrally. Implementation sketch:

useEffect(() => {
 if (recommendations.length && croppedImage) {
   const topStyle = recommendations[0];
   generateAndWatermarkPreview(croppedImage, topStyle.name, `temp_${topStyle.id}`, aspectRatio, { watermark: false })
     .then(({ previewUrl }) => {
       // store previewUrl in a context or state (like previewUrls state) keyed by style.id
       setPreviewUrls(prev => ({ ...prev, [topStyle.id]: previewUrl }));
     });
 }
}, [recommendations]);
Alternatively, leverage useStylePreview by programmatically “clicking” the top style: call onStyleSelect(topStyle.id, topStyle.name) followed by onComplete if needed. But more direct is adding to preview cache. - QA: - Verify that upon upload, the network request to generate preview for the first style is initiated without user action. - Ensure the first preview appears in the UI (style card or main canvas) after upload, with no extra clicks. - Test that if the user quickly selects a different style before auto-gen completes, the app still generates that style normally (and doesn't double-charge if first one completes later – it should just be cached). - Confirm that the watermark is present on the auto-generated preview (it should be, since our generation function adds it[92]).

2. Remove Manual “Generate” Button & Streamline Style Selection UI
- Files: src/components/product/components/StyleCardButtons.tsx, src/components/product/StyleCard.tsx.
- Change: With auto-generation, the explicit “Generate This Style” button is no longer needed. In StyleCardButtons, the logic showGenerateButton[93][94] should always be false (because we auto-generate on selection). We can remove or hide that button. Instead, clicking a style card itself will trigger generation and eventually enable the “Continue” button. We might adjust useStylePreview.handleClick so that it not only triggers generation but also immediately marks that style as selected (so the UI provides feedback). Possibly, if generation is quick enough, we can auto-enable Continue once preview is ready. - Also: Ensure only one primary CTA is visible once a preview is generated: the “Continue with This Style” green button[27]. It should appear as soon as the preview is available (as it does now). The user can click it to proceed. - QA: - Confirm that upon clicking any style card, it immediately begins generation (maybe show a spinner on that card) and the “Generate” button does not appear. - Check that when the preview finishes, the “Continue” button shows up for that style. - No other style should show a Continue unless selected. - Verify we didn’t break the “Use Original” flow: style id 1 (“Original”) had a special case button[95]. That should still appear if they click original style (since no generation needed). - Try an error scenario (simulate preview generation failure) – the Retry button should still appear as per logic[96].

3. Emphasize Hero CTA & Instant Upload
- Files: src/components/Header.tsx, src/pages/Home.tsx or landing hero component.
- Change: Ensure the primary call-to-action on the homepage/landing is prominent and leads directly into upload. In Header, we already have “Start Creating” link to /product with a gradient button[8]. We will keep that text (it’s good). We might also duplicate a big CTA in the hero section of the Home page (if one exists) that does the same. E.g., in the hero component (maybe ElectricBloomHero or a generic hero), make sure there’s a large button that either scrolls to the upload section or navigates to /product. - If needed, we add an onClick handler to the hero CTA to call the file input on /product if already on that page. But since the CTA goes to route, not needed. - QA: - Check the homepage: the “Start Creating” button should be immediately visible on load (above the fold, proper contrast). - On clicking it, the user lands on /product and sees the upload interface without any other action needed. - Test on mobile: ensure the CTA is not hidden behind the hamburger menu. The header shows it in menu for mobile as well[97] – clicking that should do the same. - If possible, measure how quickly a new user can reach the uploader – it should be one click from landing.

4. Implement Persistent Bottom Bar for Checkout (Mobile focus)
- Files: src/components/product/StickyOrderCTA.tsx, src/components/product/ReviewAndOrder.tsx, src/components/product/order/OrderActions.tsx.
- Change: We will activate the StickyOrderCTA component for the final order step. Currently, it exists but might not be used. In OrderActions.tsx (which likely contains the “Place Order” button and total on the review page[98]), we can replace or augment it with StickyOrderCTA. For mobile, we might hide the inline Order button and only show StickyOrderCTA. Implementation: - Set isVisible={true} on <StickyOrderCTA total={total} onPlaceOrder={...} /> and include it in ReviewAndOrder rendering. Possibly mount it only on small screens via CSS (the component itself handles hidden on desktop by different layout inside). - Ensure onPlaceOrder triggers the same logic as the current “Complete Purchase” button (likely calling stripe or showing PaymentForm). If currently PaymentForm is embedded, we might integrate differently. Possibly, instead, we use StickyOrderCTA primarily as a display on mobile that scrolls to PaymentForm or just to show total + a button anchor link. But for simplicity, onPlaceOrder can attempt to submit the PaymentForm if using Stripe Elements (we might need a ref to PaymentForm or to call a context). - If that’s too complex, as interim, we can at least use StickyOrderCTA to mirror the info and instruct user to scroll up to the form. But ideally, we handle it. - QA: - On a mobile viewport, go through to the final Review step. Verify that a fixed bar appears at bottom with the total and an “Order Now” (or “Place Order”) button[2]. - Tap the button: it should initiate checkout (either by submitting payment or navigating). If PaymentForm is on same page, perhaps tapping could scroll to it or open Stripe. We need to ensure no double submission issues. - On desktop, ensure this bottom bar does not overlay (the component itself has hidden sm:flex inside for desktop layout[52]). - Test different totals (e.g., with AR added) – the bar should update the total figure accordingly. - Check that the bottom bar does not cause any layout shift on appearance (we fix it at bottom). The main content likely has enough bottom padding to not be hidden behind the bar. - Also check focus order: tabbing on mobile (if keyboard used) should reach the “Order Now” button eventually (though mobile tabbing is rare, we still care).

5. Guest Checkout & Magic Link Flow
- Files: src/components/product/order/CustomerInformation.tsx (if exists), supabase/functions/create-magic-link (if exists) or backend integration.
- Change: Ensure that the checkout does not demand login. Likely, currently if user is not logged in, they can still fill out CustomerInformation form (name, email) in OrderSummary[99]. We’ll confirm that. If the app currently tries to force login before payment, we’ll remove that. For example, if useAuthStore was gating checkout, we’ll bypass it. The presence of CustomerInformation fields implies guest checkout is supported. - Next, implement post-purchase account creation: after payment success, if the user was not logged in, trigger sending a magic link email. Possibly we’ll create a Supabase function to invite user. But Supabase Auth has an Admin API to send invite emails. Implementation: In PaymentSuccess.tsx (there is likely a page) or in the success callback, check if !user && emailProvided. Then call Supabase or backend endpoint to send magic link. This may require writing a cloud function or using the Node admin. Perhaps simpler: show a message on success: “Create an account to save your artwork” with a button that triggers sign-up using the email. But that deviates from “fully automatic”. Time permitting, we try the automated email approach. - QA: - Run through a purchase flow as a logged-out user. Verify you can complete it without any login prompt. - Ensure the order still gets recorded (in our DB or at least stripe) with the provided email from CustomerInformation. - After purchase, check that a magic link email is received (if configured). If we can’t simulate email, at least ensure our logic to send it runs without errors. - Also verify logged-in user path still works (if user is logged in, they skip CustomerInformation perhaps and we use their profile email). - Edge case: If a guest uses an email that already has an account, sending a magic link could just be a sign-in link. We should handle the response (Supabase may return an error if user exists). In that case, perhaps instead prompt “We noticed you have an account, please sign in to view your order.” This might be beyond scope, but mention as risk.

6. (Bonus if time) Prefetch & Cache Improvements for Speed
- Files: src/hooks/useRoutePrefetch.ts, index.html.
- Change: Not critical, but we can add a <link rel="preconnect" href="https://<SUPABASE_URL>"> in the HTML head so that DNS/TLS handshake to Supabase is done early (improving preview fetch time). Also, in useRoutePrefetch, confirm we prefetch the heavy routes. Already sees product and auth prefetch[84][86]. That’s fine. We may add prefetch for PaymentSuccess route after checkout started. - QA: - This is hard to verify directly, but we can check the network waterfall in dev tools: the TLS connection to supabase storage or function should show as already established by the time we call it. - No negative impact (preconnect is generally fine).

Sprint 1 Testing Checklist: After implementing these, we will test end-to-end: - Upload to first preview time (with network slow 3G simulation) – ensure it’s improved. - Each stage’s UI for clarity (only one primary action visible at a time). - That no major console errors or broken state transitions occur (especially around StepOneExperience which ties into a lot of things). - That performance metrics in Lighthouse are trending better or at least not worse.

Sprint 2 – Enhanced Studio UX, Upsells, and Performance Polishing
1. Merge Canvas Config & Customization into Studio Screen
- Files: src/components/product/ProductStepsManager.tsx, src/components/product/components/CanvasConfigurationStep.tsx, src/components/product/components/CustomizationStep.tsx, src/components/product/StudioCanvasScreen.tsx (new).
- Change: This is a larger refactor. We will create a new component, say StudioCanvasScreen, which is shown once Step 1 is completed. In ProductStepsManager, instead of showing distinct Step 2 then Step 3, we can do:

{currentStep >= 2 && <StudioCanvasScreen />}
This StudioCanvasScreen will encompass both size selection and customization options with the preview. - Implementation details: - In StudioCanvasScreen, layout a grid: left side (or top on mobile) is the CanvasPreviewSection (showing the generated art on a wall or canvas mockup)[88]. Right side is the options: we embed SizeSelectionSection (from CanvasConfigurationStep) and CustomizationOptions together. Possibly as accordion tabs or simply one after the other. - We reuse existing sub-components: e.g., OrientationSelector (if present) to let user swap orientation if they want (that was part of CanvasConfigurationStep). - We ensure changes like orientation or size trigger a preview update or at least reflect in the mockup. (Orientation change may require regenerating the image in new aspect – our state management might already handle: useProductFlow probably resets preview on orientation change[24]. We have to connect that: when user picks portrait vs landscape, call useProductFlow.setOrientation which in turn might clear previewUrls requiring regeneration. This is complex but we follow existing patterns). - We must maintain gating: user shouldn’t checkout without choosing a size. We’ll initialize selectedSize with a default (maybe the smallest size) to avoid needing a mandatory step. The code currently might default selectedSize empty until user picks in Step2. We can default it to “12x16” or highlight a recommended one. The PsychologyOptimizedSizeGrid likely auto-selects one on render if not selected – if not, we implement a default selection on mount of StudioCanvasScreen (e.g., call onSizeSelect for the median size). - Remove the individual Step 2 and Step 3 components from rendering, to avoid duplicate UI. - QA: - Flow: After style selection, the UI should now show the combined studio. Confirm that the previously selected style’s preview is shown large on the canvas preview area. - Test selecting a canvas size: the price updates immediately (PricingSummary should reflect basePrice accordingly[100]) and the preview aspect ratio may change if orientation changes with size (e.g., 8x10 vs 8x8). - Test toggling frame color: the canvas preview outline should change (the useCanvasPreview provides canvasFrame props to CanvasPreviewSection to draw frame). - Toggle the Living Memory: the AR marker (QR code) might appear on the canvas preview (if we choose to visually indicate AR Ready). Currently, not sure if CanvasPreviewSection adds an AR badge if livingMemory is true – but we could do that: e.g., overlay a small QR icon on the preview when AR is included, to simulate how the real product has a QR sticker. - Ensure all options can be used in any order (e.g., change size, then style again via style carousel if we allow? Possibly going back to style is locked after proceeding, unless they click Edit on step progress – our context should allow going back to step1 if needed by clicking step header). - Confirm that moving to checkout (clicking Add to Cart) collects all current selections properly (style, size, frame, AR flags). - Check mobile layout: likely we’ll stack preview and options vertically. The bottom bar will cover the checkout button anyway. The options might be collapsible sections on mobile for better UX (we might use accordion for “Size & Frame” and “Enhancements”). - No broken state: for example, ensure that the initial preview (which was cached in step1) is still shown in customization (the code passes previewUrls down[101][102], we must ensure that context or state is accessible in the new combined component. Possibly use the context slices as per refactor plan).

2. AR Toggle & Demo Integration
- Files: src/components/product/customization/LivingMemoryCard.tsx, src/components/product/customization/PremiumVideoOptions.tsx, public/assets/ar-demo.mp4 (example asset), src/components/product/customization/ARExampleModal.tsx (new).
- Change: We already have LivingMemoryCard UI[58]. We will add the micro-demo to it. Perhaps under the description text, insert a small div with a phone icon or an embedded video. Implementation: - Add an <img src="/phone-with-video.png" alt="AR demo" className="w-24 h-auto"> for a quick solution – we'd prepare an image that shows a phone and a play icon. Or, - Add a clickable text “See how it works” next to the “Customer Favorite” badge. This triggers a modal (ARExampleModal) which contains more elaborate demo: e.g., the QR code from InteractiveDemo[103] plus instructions. We can reuse a simplified version of InteractiveDemo in this modal for consistency (it already has a QR that links to a live demo AR experience). - For now, let's plan a static approach: embed an <img> of a QR code and phone. Possibly reuse the one in InteractiveDemo (there is an image at src="/lovable-uploads/a81e502f-..." in that component[104], but better to have our own asset). - Also, ensure that toggling the switch fires our events and updates pricing: - In LivingMemoryCard, onEnabledChange will call onCustomizationUpdate({ livingMemory: enabled })[105]. Our state then sets livingMemory true, which triggers recalculation of livingMemoryPrice = 59.99[68]. PricingSummary should then include it. We’ll verify that. - We add onEnabledChange handler to fire qr_added event when enabled is true. Similarly, if user toggles off, possibly no event or maybe track removal event (not critical). - For qr_viewed: hooking the “See how it works” link to fire this. - QA: - On customization screen, verify the Living Memory card appears with toggle off by default, $59.99 label, and perhaps a “Customer Favorite” badge[35]. - Click “See how it works” (if implemented): modal should pop up with an AR demo (scanable QR or video). Scan the QR with a phone – it should lead to a demo page (assuming we have one set up via the marketing site’s AR demo link). Ensure modal has accessible close button and focus trap. - Toggle the AR switch on: confirm the price in the summary instantly adds $59.99 (e.g., base $89 becomes $148.99 if no other adds). Confirm an analytics event (in debug console, perhaps log something) for qr_added. - Check that the state of AR stays if user navigates (like if they go back to style step and forward again – presumably state persists because we’re using context). - If voiceMatch is toggled (PremiumVideoOptions visible after enabling AR): the voiceMatch switch should only be enabled when livingMemory is true and should add $19.99. Check that toggling it changes pricing (the code calculates voiceMatchPrice only if livingMemory is true[106], which we do). We should surface that cost either by adjusting the $59.99 badge (maybe we don’t, because it's separate). Instead, PricingBreakdown likely lists “Voice Personalization: $19.99” if voiceMatch true. Let’s ensure OrderItemsList prints it. If not implemented, consider concatenating with livingMemory line (but better separate). - AR marker on preview: optional check – maybe out of scope now. But consider if we want to overlay a QR icon on the canvas preview image when AR is added (just a visual cue). We can implement that in CanvasPreviewSection if customizations.livingMemory is true: render a small QRCode icon at bottom corner of canvas in the preview. It’s purely visual. Not critical though.

3. Token/Download Path Demotion
- Files: src/components/product/components/StyleCardButtons.tsx, src/components/product/components/WatermarkRemovalModal.tsx.
- Change: Modify the UI for the download option: - In StyleCardButtons, currently showWatermarkRemovalButton controls the “Remove Watermark & Download” button appearance[107][4]. We will still compute it (so that the option shows only when a preview exists and not for style 1), but instead of rendering a full green Button, we render a smaller link-style element. - For example:

{showWatermarkRemovalButton && (
 <button onClick={() => setIsWatermarkModalOpen(true)} className="text-xs text-gray-500 underline hover:text-gray-700">
   Download HD Image
 </button>
)}
This will look like a small text link. Alternatively, an icon:

<button onClick={...} className="p-1 text-gray-600 hover:text-gray-900" title="Download image">
 <DownloadIcon className="w-4 h-4"/>
</button>
using an icon from our set. - We open the same WatermarkRemovalModal (which handles the token logic) when clicked[73]. - In the modal, we might adjust some wording too. Currently it says "Remove Watermark & Download" in the title or button[108]. We can change it to "Download Image" as title if needed, and inside say “Choose resolution to download”. Those copy tweaks for clarity. - Possibly shorten the modal: maybe default select “HD” resolution (middle one) to minimize user decisions (they can change if they want Ultra). - After successful purchase in modal, it shows "Downloaded!"[109]. That’s fine. - Ensure the modal forces login if needed. Currently, if not enough tokens and user not logged in, handleRemoveWatermark in modal sets isTokenPurchaseOpen true which opens TokenPurchaseModal[110]. If user is not logged, TokenPurchaseModal’s Purchase button is disabled (disabled={!user})[111]. This means a guest clicking download will see the token packs but cannot buy until signing in (which we should prompt maybe by popping an Auth dialog). We might need to integrate an auth prompt. Perhaps simpler: if no user, when they click our download link, instead of directly opening WatermarkRemovalModal, we first redirect them to sign-up/login (or pop auth modal) and then back. But that adds friction in style step. Given the rarity, we might accept that token purchase requires login and if they try, nothing happens (though that’s poor feedback). - To improve: we can intercept in WatermarkRemovalModal: if !user, instead of return, we pop a message “Please sign in to download” and maybe trigger setIsTokenPurchaseOpen(true) which in turn shows token packages (which itself will prompt login when they try purchase). - This is a minor edge; likely token purchasers are motivated and will find the Sign In button in header. We can live with the current approach for now, but note it. - QA: - Generate a preview for a style. Check that instead of a big green “Remove Watermark & Download” button, you now see either a small link or icon. It should not draw too much attention. Verify it’s still visible enough (maybe below the Continue button). - Click it: the WatermarkRemovalModal opens as expected. Try out the flows: * If user has tokens (simulate by logging in and using an account with balance): ensure it deducts tokens and allows download. * If user has no tokens (common case), the modal will prompt purchase. Ensure the “Purchase Tokens” button opens the TokenPurchaseModal. In that modal, since user likely not logged in, the Purchase button is disabled – try enabling by logging in, or test the scenario as a logged-in user with 0 tokens where the purchase goes through (that will open Stripe checkout ideally). We likely won't fully test Stripe here, but just ensure UI flows don’t break. * Check that after a successful watermark removal, the StyleCard now shows the Re-download button and info[76] with tokens spent etc. That info line might be fairly verbose; it’s fine for now (it actually serves to educate that they used X tokens). - Confirm that if a user ignores the download option, it doesn’t impede them – i.e., nothing about it prevents continuing. - Confirm that style 1 (Original) does not show a download link (since original image isn’t watermarked and we probably don’t allow token usage for original photo – code check: showWatermarkRemovalButton is false for style.id===1[107], so that’s correct). - Accessibility: ensure the small download link has an accessible label (the button text covers it if textual; if icon-only, add aria-label="Download image").

4. A/B Test Infrastructure for Style Layout
- Files: src/components/product/StyleSelector.tsx, src/components/product/components/HeroRecommendations.tsx, etc., plus maybe a context or util to assign variant.
- Change: Implement a simple way to switch between Grid vs Carousel for style previews. We can use a query param or random assignment: - For development, perhaps easier: read localStorage.variant or a query like ?variant=carousel to toggle. In production, one would use an experiment framework; we’ll simulate by code branching. - For example, in StyleSelector, have:

const useCarouselVariant = someLogic(); // e.g., based on a global flag
return (
 <div>
   {useCarouselVariant ?
     <CarouselStylePicker ...props/> :
     <IntelligentStyleGrid ...props/>}
 </div>
);
Where <CarouselStylePicker> is a new component we create that displays the previews one by one with next/prev controls. - Implement CarouselStylePicker: It can reuse the same recommendations data but instead of showing all, it shows the currently selected index’s preview large. We likely use the same useStylePreview hook but for one style at a time. Or simpler: the images are likely already generated by the time user sees them (due to our background generation). We can access previewUrls from context and just show the one for current index. Buttons allow cycling index. - This is moderately complex to implement fully. Given time, we might stub it (just for conceptual completeness) and not fully flesh out arrow functionality. But to truly test, we’d need it working. - Possibly skip deep implementation for now due to time. Instead, just outline how we would release it behind a feature flag. - QA (planned): - When variant is set to carousel, verify that the style selection UI shows one large preview and that clicking “Next” loads the next style’s preview (if already generated or triggers generation). - Confirm the events style_selected still fire appropriately (should when user hits continue after picking style). - Ensure user can still access all styles (through swiping or arrows). - On grid variant, verify nothing changed from baseline except improvements we did (auto generation, etc.). - We'll monitor metrics via the events as described, but that’s post-deployment.

5. Performance Finishing Touches
- Files: src/components/product/photo-upload/PhotoUploadContainer.tsx, vite.config.ts (if needed for chunk splitting), and general scanning.
- Changes: Apply the code-splitting and lazy loading for heavy components: - Lazy load PhotoCropper: As described, in PhotoUploadContainer, do not import PhotoCropper at top. Instead:

const Cropper = React.lazy(() => import('../PhotoCropper'));
...
{showCropper && uploadedImage &&
 <Suspense fallback={<div className="text-center p-4">Loading editor...</div>}>
    <Card>... <PhotoCropper ... /> ...</Card>
 </Suspense>
}
Also handle when user finishes cropping, we can unmount it to free memory. - Lazy load TokenPurchaseModal: The token purchase flow is not needed until someone clicks that. We can lazy import it in WatermarkRemovalModal when needed. The code now imports it statically[112]. We can do similar lazy for that modal’s content if we want to shave a few KB. Not critical since it’s fairly small. - Dynamic import of routes/components: If not already, ensure pages like PastelBliss.tsx and others are code-split. Possibly use React.lazy for those routes in the router. These pages are likely marketing style landing pages – they might be loaded on demand if routes are separate. If they are all included in main, we should split them. But since they have separate chunk names (pages/PastelBliss etc.), maybe Vite already splits route-based on code (if using something like React Router with import statements, it might not auto-split – but if these pages are imported in a central router, they might be in main bundle). - We can refactor the router (maybe in App.tsx or index.tsx) to lazy load each route component. - Remove unused code: run the dead-code tool if possible. If, say, ClassicOilPainting.tsx is identical to others and we plan to unify them, maybe mark for later deletion. For now, just ensure nothing obvious like an old context or service is left. - Image optimization: convert static images (logo, etc.) to optimized formats if needed. E.g., wondertone-logo.png loaded in header[113] could be a small optimized PNG or SVG if available. This is minor (logo likely small). - Lighthouse audit: After building, run a Lighthouse on a simulated Moto G4 4G. Check metrics. If LCP is still high, identify cause (maybe large images). - Possibly the first preview might not be ready by LCP time in audit, so LCP might be the upload card (which is fine, that should be lightweight text and shapes). - If the gradient backgrounds or animations cost paint time, consider using simpler CSS or disabling heavy filters on low-end devices (the upload dropzone uses backdrop-blur and multiple radial gradients[49] – might be a bit heavy. But in worst case, we keep it as design unless perf test shows it’s problematic). - CLS check: ensure Lighthouse CLS comes as ~0.0x. If any shift flagged, fix it (common one could be if the dynamic content like an image pushes something). - Example: The unified SocialMomentum popup (if any) might not be present initially but might appear. But it’s absolutely positioned, so probably no shift. - Focus & ARIA: Quick audit with Axe or similar for accessibility issues. Fix any critical ones (like missing alt on images – ensure all <img> in our UI have alt, e.g., the previews should have alt like “<StyleName> preview”). We can set alt={${styleName} preview} in StyleCard image element. - **QA:** - Open the app in incognito (no cache) on a moderate device. Measure time to interactive and first contentful paint. It should feel snappy – e.g., upload dropzone visible quickly. - Test using throttling (Fast 3G) to ensure our spinners and messages show appropriately (no long blank screen). - Interact with lazy-loaded parts: click “Edit Photo” to open cropper – verify there’s a slight delay as chunk loads but it shows the fallback and then the crop UI appears properly. Crop an image to ensure lazy component works fully (no missing hooks). - Try token purchase flow – the TokenPurchaseModal being possibly lazy might cause a tiny delay when opened – ensure it appears and content is correct. The user likely expects a slight modal load, that’s fine. - Confirm we haven’t broken any error logging or security aspects (thesecurityLogger.ts` might log certain actions – just ensure no console errors if we didn't modify that). - Memory leak check: after navigating or closing modals, ensure no processes lingering (hard to verify manually, but at least see no unusual console warnings).

Sprint 2 Summary: After these changes, we will again run through full flows: - Create an order with all options (choose style, change orientation, add frame, add AR, use token or skip) to see that everything works end-to-end. - Also try a quick path (upload and immediately click add to cart, leaving defaults) to ensure minimal friction still works (should pick default size and no frame by default and go to checkout). - Check performance counters in devtools performance profiler for any obvious long tasks at load.

We will flag any remaining issues and either fix or document as known limitations, but aim to meet the acceptance criteria fully.

11. Assumptions, Risks, and Open Questions
Throughout this plan, we made some assumptions and identified a few risks:

Assumptions: - Caching & Cost: We assume the backend (Supabase Edge Functions + Replicate) has caching such that generating multiple style previews for one photo won’t exponentially increase cost. The README indicates caching in generate-style-preview[114] and the guardrails emphasize not duplicating requests[115]. We proceed assuming generating ~3 previews per user is acceptable. If each preview costs an API call, we believe this is within acceptable range for conversion gain, but it’s a business decision (cost per preview vs LTV). We assume product owners are okay with slightly higher AI inference costs for higher funnel completion. - Default Size Selection: We assume one canvas size (likely the smallest, 8x10) can be pre-selected by default without user input, to streamline the flow. This avoids forcing the user to pick a size in a separate step. We choose a mid-priced default ($89 for 12x16 or $49 for 8x10[116]). We assume this is acceptable and that users can change size if they want a different one. This assumption needs confirmation: if the business absolutely needs user to confirm size explicitly, we might need to retain a step or a required selection. - No required login for purchase: We assume it’s acceptable (and desired) to allow guest checkout. The code and our strategy align on this: the presence of a CustomerInformation form suggests guest checkout is planned[99]. We further assume sending a post-purchase magic link is feasible via Supabase (it has an invite mechanism or we can generate a token ourselves). We proceed with that strategy as it meets the "guest until value" goal. - User technical ability: We assume users have basic proficiency to handle the UI changes (like toggling AR, understanding scanning a QR code). The AR explanation is geared to be simple (no app needed, just camera scan). We expect that’s enough given the target audience likely has seen QR menus etc. - Supabase functions in dev: We assume during dev/test we have the necessary Supabase env (VITE_SUPABASE_URL) and the edge functions running so preview generation and watermark removal actually work. If not, we’d test with stub images. For final QA, we need the backend up. - Stripe integration: We assume the current Stripe flow (for physical checkout and token purchase) is working or at least stubbed in dev. We won’t modify its core logic, just how it’s triggered (via bottom bar etc.). We assume Stripe test keys are set for dev to test a payment through. - Timeline & Two Sprints: We assume we can implement and test the bulk of these changes in roughly 2 sprint cycles (~2-3 weeks). The plan is scoped accordingly, though some parts (full A/B infra, deep refactor) are ambitious but manageable with the existing code structure as a guide.

Risks: - Preview Generation Latency: There’s a risk that generating multiple previews sequentially might actually slow down the first preview if not handled right. We plan to trigger the first one immediately and subsequent ones after, but if the server queues requests, doing 3 back-to-back could mean the first finishes slightly later than if it were alone. We mitigate this by not truly parallelizing all – we send the first, wait for at least its status to be processing, then fire next. Also caching might make 2nd/3rd faster if they use same base model with different style prompts (hard to know). We accept a small risk here; if data later shows it hurts first preview time, we might scale back to 1 immediate + 1 background rather than 3. - State Management Complexity: Combining steps introduces risk of new bugs – e.g., ensuring that when orientation is changed at customization, the previews refresh properly. We rely on context and existing hooks to manage this. We must test edge cases like switching orientation or recropping after already selecting style – does the system regenerate the preview with the new aspect? Possibly not automatically. The StepOneExperience & useProductFlow might reset selectedStyle when orientation changes[24], forcing user to re-generate. We need to verify this flow and ensure it’s communicated to user (maybe a small alert “Image reoriented, please regenerate style” or we auto-regenerate in background after orientation change). This complexity is a risk we need to carefully QA. - UX Overwhelm: With the Hybrid studio, some users might be confused about what to do next if not guided. We try to mitigate with subtle guidance (e.g., maybe highlight the size section with a pulsing border saying “2. Choose size” for a few seconds). If not done, there’s a risk a user might not realize they can scroll or that they need to choose a size. However, since we default a size, the “Add to Cart” button is active anyway, so in worst case they skip customizing and just checkout the default. That’s not terrible, but we want them to notice AR upsell etc. We assume users will scroll naturally to see what options exist, especially on mobile if they see content below. - Token Purchase Flow For Guests: As noted, if a not-logged-in user tries to buy tokens (download image), the current UI might not strongly force login. This could cause confusion (“why is purchase button disabled?”). We might need to add a clearer prompt. This is a small subset, but a risk to UX completeness. We marked this for improvement possibly by triggering the Auth modal when purchase disabled due to no user (Open question: implement a quick auth modal on the fly?). Due to time, we might leave it and count on the “Sign In” button in header or perhaps we add a note in the TokenPurchaseModal: “Please sign in to purchase tokens.” Actually, we can do that easily: if !user, instead of disabling silently, change the button to “Sign in to Purchase” and onClick -> navigate to auth. - SEO Impact: By simplifying/demoting the download path and combining steps, we might have changed some content structure. E.g., if those style landing pages (ClassicOilPainting, etc.) were for SEO with static content, we haven’t changed them except code-splitting. Our changes mostly in the interactive flow likely have no negative SEO impact (they might improve performance which is good for SEO). The content on those pages remains. - Analytics Overhead: We’ll be adding event logging. We assume this is fine and not hitting any privacy issues (we’re not logging PII, aside from perhaps style ids and times which are fine). We should ensure these events don’t slow down the app. If using something like console.log for dev, remove it in prod or use a non-blocking method (most analytics SDK are async). - Mobile UI Crowding: There’s risk that on a small screen, showing preview plus many options (size, frame, AR, etc.) could require a lot of scrolling. We mitigated with a sticky bottom bar (so CTA is always present). But users might not see e.g. the AR toggle without scrolling. That’s acceptable; not everything can be above fold on mobile. We just need to ensure the layout is tidy and doesn’t break. We’ll test on a typical phone size. - Feature Creep in PremiumVideoOptions: The AR premium enhancements (voice match, etc.) are quite advanced and currently mostly UI. If a user enables those, do we actually handle it in backend? The OrderSummary calculates costs for them[117], but can we fulfill them? Possibly not fully implemented yet (like voice cloning might be future). This is a product question: should we expose those if not ready? If not, we might hide or disable those toggles for now. (Open question to founders: are voiceMatching and backgroundAudio functional?). As a precaution, we could hide PremiumVideoOptions behind a flag or if those features aren’t ready we leave them as dummy toggles (cost is calculated though, which is odd if not delivered). Risk: selling something not delivered. We assume they plan to deliver these soon, so we leave the UI but perhaps mark them as “Beta” or such if needed.

Open Questions: 1. Orientation and Cropping logic: When a user changes orientation after a preview is generated, do we have a hook to regenerate the preview for the new aspect? The context shows orientation changes clear cached previews[24]. But how is the user prompted to regenerate? We should clarify expected behavior: - Option 1: automatically regenerate immediately on orientation change (could be expensive if user toggles back and forth). - Option 2: require the user to hit a “Refresh preview” button after orientation change. Currently, usePreviewGeneration likely handles this by marking previews stale, and maybe StyleCard shows the “Generate” button again if orientation changed (because selectedOrientation in state changed). We need to confirm this by reading useProductFlow or usePreviewGeneration. Given time, I’d ask: Should we auto-regenerate previews when user switches orientation? If yes, implement it (trigger generate for currently selected style again). If no, ensure the UI clearly indicates they should re-generate (maybe style cards revert to “Generate” state). This affects UX and performance (we lean toward auto since it aligns with instant philosophy). 2. Account requirement for Digital Download: If a user never creates an account, downloads an image, then later closes the session, do we have a way for them to retrieve that image again? Likely not – but they have it saved locally, so maybe fine. However, what about the token balance they bought? If they bought tokens as guest, that scenario is impossible because we require sign-in to buy tokens. So no one can actually spend money on tokens without an account. So that’s covered. Perhaps no open question – the system ensures any token purchase ties to an account. 3. Should the “Download Image” option be removed entirely after purchasing a canvas? Perhaps not necessary – if someone buys a canvas, they might still want a digital copy. We currently allow both. A user could add canvas to cart and also download the image via tokens. That’s fine – extra revenue. We’ll leave that. 4. Order of Color Frames and AR in UI: We placed AR below frame in customization. Does it make sense or should AR be highlighted above frame to push it more? We assumed frame is a more expected option, so it comes first. But AR is high value and unique – maybe it should come before frame to catch attention. This is a design choice; our assumption is frame is simpler, do it first, then AR as the “wow” upsell last. Open to adjust if needed by stakeholder feedback. 5. Voice Match viability: As noted, if voice matching (the idea of recreating a loved one’s voice) is not yet actually implementable, we might need to hide that toggle to avoid selling something we can’t deliver. We need clarification from product owners. If in doubt, we can leave the UI but maybe add a tooltip “Coming soon” or something. This likely requires an answer from stakeholders. 6. Testing A/B in production: Do we have a framework or do we roll our own? If none, I proposed a simple approach. If precise experiment management is needed, we might integrate something like Google Optimize or LaunchDarkly. That’s beyond scope here, so probably fine with a code flag. But open question: how will we determine assignment? Possibly use the user’s Supabase ID mod 2 to assign variant, so it’s sticky per user. Or simpler: random on page load (not ideal if same user might see different on refresh). For initial smaller test, random is okay. We mention sample size needed, which might require running for a while to gather data. 7. UX for multiple style exploration: With auto-generation, one potential concern: the moment user clicks a style, we auto-generate and then if they click “Continue” immediately, they might not realize they could have scrolled to see other styles. Are we okay with that? Possibly yes – if the first style meets their needs, great. If not, presumably they will naturally click on a different style tile to see another. We should ensure that’s smooth: clicking another style card should fetch its preview quickly (some might be already preloaded as we plan). We'll trust user curiosity here. An alternative is to show multiple previews at once (which we are partially doing by generating a few). That’s basically what we do with grid. So question: do we want to show 2-3 previews side by side automatically? That could overwhelm layout, so not unless we redesign to a mosaic. We decided sequential user-driven is fine. 8. Magic link deliverability: When we send a magic link email on purchase, we assume the email won’t end up in spam and user will actually use it. Some might ignore it. That’s acceptable – at least the account exists in our system. We might mark it as optional for them. This is more an FYI; no immediate answer needed, but something to monitor if many purchases remain unclaimed accounts. 9. Edge cases on mobile: We should confirm if certain devices (Safari iOS) handle our features properly (e.g., file upload, canvas display). And ensure no critical functionality relies on hover (which mobile lacks) – for instance, the style info should be visible without needing hover. We mostly use clicks, so likely fine. 10. Team alignment on style changes: The refactor is a significant overhaul of the UX. We should validate with stakeholders if these changes align with their vision. Particularly: - Are we okay removing the step-by-step progress bar beyond step 1? (We’ll still show maybe steps, but step 2 and 3 are merged, so that progress indicator might need adjusting. Perhaps still show 3 steps but step 2 is just “Customize” including all.) - Are we okay heavily emphasizing the AR upsell? (They did call it out as AOV lever, so yes). - The demotion of digital – stakeholders likely want that, given emphasis on canvas revenue, but we should confirm that they don’t intend to push a digital-only product equally. These are more verification questions for the team rather than implementation blockers.

In conclusion, most of these open points can be addressed with product input or minor adjustments during development. We have contingency plans (e.g., hide unfinished options if needed).

We will maintain close communication with the team on any assumption that might not hold, especially regarding the readiness of features like voice matching and acceptable trade-offs in auto-generating multiple previews. Our implementation will be flexible so we can tweak numbers (how many previews to auto-gen, which default size to choose) based on actual usage data or feedback.

ADDITIONAL Information FROM A SEPERATE CODEX CONVERSATION: 

CODEX-DEEP-RESEARCH.MD then read WONDERTONE-UX-STRATEGY.MD
# Wondertone UX & Conversion Strategy — Codex Perspective


## 1. Core Experience Model: Guided Launchpad → Immersive Studio
- **Launchpad Step (existing Step One)**. Recompose the current accordion body so the cropper, SmartProgress, and ContextualHelp stay on the left while the IntelligentStyleGrid scrolls on the right. This keeps `StepOneExperienceProvider` intact (`src/components/product/components/PhotoAndStyleStep.tsx`) and still gates progression through `useProductFlow.canProceedToStep`.
- **Persistent Preview Rail.** Surface the latest generated preview inside Step One using the data already passed to Step Three via `preview.previewUrls` (`src/components/product/components/ProductStepsManager.tsx`). This lets users evaluate art while browsing styles without waiting for later steps.
- **Studio View for Steps 2–4.** After Step One marks complete, expand a “Studio” panel that consolidates size, frame, AR, and review details inside a single canvas layout. We can keep the stepper logic but present the remaining accordion sections as tabs so orientation resets, preview clearing, and StepOne telemetry remain unchanged (`src/components/product/hooks/useProductFlow.ts`).
- **Always-on Order Rail.** Reuse the progress and pricing logic from `BottomMomentumPopup` and `ReviewAndOrder` to maintain a sticky “Ready to Order” card across the Studio view, ensuring upgrades stay visible as users tweak settings.


## 2. Instant Wow: Make Previews Feel Immediate
- **Parallel, Prefetched Generation.** Extend `usePreviewGeneration.generatePreviewForStyle` to accept an array and fire the top recommended styles concurrently. IntelligentStyleGrid already computes recommendations (`src/components/product/components/IntelligentStyleGrid.tsx`), so trigger generation once `usePhotoUploadLogic` finishes the "analyzing" stage (`src/components/product/photo-upload/hooks/usePhotoUploadLogic.ts`).
- **Optimistic Preview Skeletons.** Replace the spinner with the blur/skeleton utilities defined in `index.css` so StyleCard shows a color-matched placeholder while polling completes. This drops perceived wait time without touching watermarking (`src/utils/previewGeneration.ts`).
- **Lazy Watermark Application.** Show the raw preview URL immediately, then call `watermarkManager.addWatermark` inside `requestIdleCallback` to avoid blocking the first frame (`src/utils/previewGeneration.ts:78-91`).
- **Edge Cache Warmth.** Use the existing prompt warm-up scheduler in the Supabase function (`supabase/functions/generate-style-preview/index.ts`) to pre-render hero styles against three sample photos, feeding an on-page manifest that renders “instant” examples before upload.
- **Error Reporting.** Emit analytics when `generationErrors` gains an entry so the team can monitor Replicate/Supabase slips and triage quickly (`src/components/product/hooks/usePreviewGeneration.ts:58-68`).


## 3. Funnel & Conversion Strategy
- **Hero Demonstration First.** Replace the copy-led homepage (`src/pages/Index.tsx`) with an autoplay transformation reel that funnels visitors into `/product` with a recommended style passed through navigation state, mirroring the existing style landing pages.
- **Guest-First Checkout.** `useStripePayment` currently hardcodes `guest@example.com`. Capture the email collected in `CustomerInformation` and pass it into the hook so receipts align while still delaying account creation until after purchase (`src/hooks/useStripePayment.ts`, `src/components/product/order/CustomerInformation.tsx`).
- **Canvas as Default Path.** In `StyleCardButtons`, demote the green “Remove Watermark & Download” CTA to a tertiary link and keep “Continue with This Style” visually dominant. Downloads remain accessible but cease competing with the primary journey.
- **Bundle the Digital Upsell.** Add a “Canvas + Instant Download ($14.99)” toggle inside `OrderSummary`. The pricing scaffolding already isolates line items (`src/components/product/OrderSummary.tsx`), so feed the selection into the Stripe item builder (`src/components/product/order/OrderActions.tsx`). Follow up with an automated drip that reminds digital-only buyers what the canvas looks like on a wall.
- **Measure the Funnel.** Hook style-selection, preview-success, preview-failure, AR modal, and checkout events into the existing performance/analytics utilities (`src/utils/performanceMonitor.ts`, `src/components/product/progress/useStepOneExperience.ts`). This closes the current gap where the social widget infers hesitation but no hard data exists.


## 4. Visual & Interaction Language
- **Palette Refinement.** Adjust the CSS variables in `index.css` to a deeper gallery purple for primary backgrounds and a muted gold accent for premium actions. Update the Tailwind config to expose `accent-gold` tokens for consistency (`tailwind.config.ts`).
- **Premium Button Recipe.** Create a `PrimaryButton` variant (shimmer gradient, rounded, hover lift) and re-use it across hero CTAs, style cards, and sticky rails so the brand’s signature action feels cohesive.
- **Motion Principles.** Apply blur-in focus for preview reveals, crossfade for style swaps, and slide-right for step advancement leveraging the animation utilities already registered in Tailwind (`tailwind.config.ts:68-139`). Favor `transform` over `filter` to stay GPU-friendly as mandated in `agents.md`.
- **Twin Landing Parity.** Factor the sticky CTA and scroll watcher shared by `ClassicOilPainting` and `WatercolorDreams` into a common hook so both pages evolve together without pixel drift.
- **Canvas Context.** Wrap previews in a “lightframe” container that mirrors the Review mockup, giving users a sense of physical scale while staying within existing layout contracts (`src/components/product/ReviewAndOrder.tsx`).


## 5. Living Canvas (AR) Integration
- **Post-Wow Modal.** After the first preview lands (`usePreviewGeneration` sets the corresponding URL), delay two seconds and auto-open a modal introducing Living Memory with a looping demo clip. This capitalizes on the emotional peak before users advance to Step Two.
- **Inline Visual Proof.** Embed a miniature phone-with-video loop directly inside `LivingMemoryCard` so the value prop is visible even without opening the modal (`src/components/product/customization/LivingMemoryCard.tsx`).
- **Preview Badge.** When enabled, overlay a QR glyph on the canvas preview inside `CustomizationSelector` to reinforce the upgrade visually (`src/components/product/CustomizationSelector.tsx`).
- **Dynamic Pricing + Analytics.** Expand `PremiumVideoOptions` to surface cost deltas in real time and emit `living_canvas_modal_shown`, `living_canvas_added`, and `living_canvas_declined` events through the analytics layer. Use these signals to A/B test placement (post-preview vs. checkout reminder).


## 6. Performance & Technical Health Priorities
- **Bundle Diet.** Tree-shake Radix imports, swap `lucide-react` for direct icon modules, and remove `@tanstack/react-query` now that token balance uses Supabase RPC (`package.json`, `src/hooks/useTokenBalance.ts`). Configure manual chunks in `vite.config.ts` to isolate React, Supabase, and UI libraries for better caching.
- **Pricing Consistency.** Align Living Memory pricing across the funnel—Review currently charges $19 while OrderSummary lists $59.99 (`src/components/product/ReviewAndOrder.tsx`, `src/components/product/OrderSummary.tsx`). Settling on one price removes trust-breaking discrepancies.
- **Cache-First Preview Retrieval.** Before invoking the edge function, compute the cache key client-side (image digest, style, orientation) and attempt a Supabase storage lookup. This reduces duplicate Replicate requests and taps into the metadata the edge already stores (`supabase/functions/generate-style-preview/index.ts`).
- **Robust Error Surfacing.** Pipe generation failures into toast notifications and analytics, offering a retry CTA that respects the existing debounce guards (`src/components/product/components/StyleCardButtons.tsx`).
- **Testing & Observability.** Add automated lint/build/deps runs (already scripted) to CI, pair a minimal Playwright smoke suite for the configurator flow, and expose preview latency stats through `performanceMonitor.getSummary()` to keep “time-to-wow” visible.


---
**Execution Roadmap (Suggested Order)**
1. Prototype the Launchpad/Studio layout on a feature branch, ensuring all guardrails (StepOne telemetry, gating) remain intact.
2. Implement multi-style pre-generation + optimistic skeletons behind a flag; compare perceived preview latency before/after.
3. Roll out Living Canvas modal + inline demo, instrument analytics, and test conversion impact.
4. Harmonize pricing, bundle trimming, and cache-first logic to stabilize performance before marketing pushes.
5. Layer in funnel analytics and testing harnesses so future experiments can run with confidence.


This plan keeps Wondertone’s four-step flow, maintains StepOne instrumentation, respects `usePreviewGeneration` as the single preview source, and positions the Living Canvas upsell as the emotional crescendo—all while driving faster “time-to-wow” and higher canvas conversions.


## Appendix: Alignment with Prior Analyses
| Theme | CODEX-DEEP-RESEARCH | WONDERTONE-UX-STRATEGY | Codex Synthesis |
| --- | --- | --- | --- |
| **Core flow** | Hybrid “Art Studio” (guided step → studio workspace). | “Magic-First” single studio; replace sequential gating. | Launchpad → Studio keeps four-step skeleton but refactors UI to mimic studio feel while preserving gating and telemetry. |
| **Time-to-wow** | Auto-generate top styles post-upload; instant preview rail. | Pre-generate multiple styles, blur placeholders, parallel requests. | Parallel generation + optimistic skeletons + lazy watermarking, leveraging existing hooks without full rebuild. |
| **Checkout & auth** | Guest-first with post-purchase account creation. | Remove auth friction until value delivered. | Reuse existing Stripe hook but feed real emails from checkout while delaying account creation—aligns with both. |
| **Digital downloads** | Demote “Remove watermark” to secondary action; keep upsell. | Focus canvas path, digital as side quest. | Tertiary download link + bundled canvas+digital upsell preserves both insights. |
| **Living Canvas (AR)** | Highlight AR in customization and review with visual demo. | Elevate Living Memory as hero upsell with analytics. | Post-preview modal + inline demo + analytics wiring; incremental delivery consistent with both. |
| **Performance priorities** | Bundle trimming, persistent preview caching, prefetch hero previews. | Cache warm-up, retry logic, performance instrumentation. | Manual chunking, icon tree-shake, cache-first preview fetch plus expanded telemetry. |


### Key Deliberate Deviations
- **Preserving Gating Logic.** WONDERTONE-UX-STRATEGY pushes for abandoning the sequential flow; I opted to retain `useProductFlow` gating to respect guardrails while still delivering a studio feel.
- **Incremental Rollout.** CODEX-DEEP-RESEARCH suggests collapsing Steps 2 & 3 immediately; my roadmap phases this change so telemetry, orientation resets, and preview cache contracts stay stable during migration.
- **Watermark Handling.** Prior docs focus on server-side watermarking; I recommend lazy client watermarking first to cut perceived delay, with server moves later if needed.


### Additional Opportunities Inspired by Both
- A/B test early Living Canvas prompts (modal vs. checkout banner) once analytics events are in place.
- Layer guest checkout email capture with optional post-purchase account creation to validate conversion lift assumptions.
- Use the performance monitor hooks to publish “time-to-wow” dashboards, mirroring both documents’ emphasis on measurement.
